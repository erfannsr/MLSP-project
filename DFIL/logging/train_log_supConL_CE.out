nohup: ignoring input
/home/erfan/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/erfan/miniconda3/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
????
/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Train_small2/Real/*.jpg
('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Train_small2/Real/real_0.jpg', 0) ('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Train_small2/Real/real_10.jpg', 0)
/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Train_small2/Fake/*.jpg
('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Train_small2/Real/real_0.jpg', 0) ('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Train_small2/Real/real_10.jpg', 0)
the number of images:  70002
????
/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Validation_small2/Real/*.jpg
('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Validation_small2/Real/real_0.jpg', 0) ('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Validation_small2/Real/real_1.jpg', 0)
/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Validation_small2/Fake/*.jpg
('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Validation_small2/Real/real_0.jpg', 0) ('/home/erfan/MLSP project/Datasets/Deepfake and Real images-Kaggle/Validation_small2/Real/real_1.jpg', 0)
the number of images:  19715
len(train_loader) =  8751
len(val_loader) =  2465
  0%|          | 0/10 [00:00<?, ?it/s]Epoch 1/10
----------
iteration 50 train loss: 0.34006000 Acc: 0.62500000
iteration 100 train loss: 0.35257661 Acc: 0.50000000
iteration 150 train loss: 0.27970767 Acc: 0.87500000
iteration 200 train loss: 0.26085559 Acc: 1.00000000
iteration 250 train loss: 0.27812672 Acc: 0.75000000
iteration 300 train loss: 0.28050938 Acc: 0.87500000
iteration 350 train loss: 0.25543046 Acc: 1.00000000
iteration 400 train loss: 0.28193057 Acc: 0.87500000
iteration 450 train loss: 0.27933595 Acc: 0.75000000
iteration 500 train loss: 0.25112078 Acc: 1.00000000
iteration 550 train loss: 0.26221851 Acc: 1.00000000
iteration 600 train loss: 0.29306367 Acc: 0.87500000
iteration 650 train loss: 0.25220194 Acc: 1.00000000
iteration 700 train loss: 0.26030928 Acc: 1.00000000
iteration 750 train loss: 0.24979170 Acc: 1.00000000
iteration 800 train loss: 0.26936156 Acc: 0.87500000
iteration 850 train loss: 0.25619474 Acc: 1.00000000
iteration 900 train loss: 0.25266415 Acc: 1.00000000
iteration 950 train loss: 0.28335935 Acc: 0.87500000
iteration 1000 train loss: 0.26315904 Acc: 0.87500000
iteration 1050 train loss: 0.31272191 Acc: 0.87500000
iteration 1100 train loss: 0.25899073 Acc: 1.00000000
iteration 1150 train loss: 0.25149500 Acc: 1.00000000
iteration 1200 train loss: 0.24962525 Acc: 1.00000000
iteration 1250 train loss: 0.36285466 Acc: 0.87500000
iteration 1300 train loss: 0.27526903 Acc: 0.87500000
iteration 1350 train loss: 0.24877779 Acc: 1.00000000
iteration 1400 train loss: 0.29744807 Acc: 0.75000000
iteration 1450 train loss: 0.27219605 Acc: 0.87500000
iteration 1500 train loss: 0.25055829 Acc: 1.00000000
iteration 1550 train loss: 0.30726480 Acc: 0.75000000
iteration 1600 train loss: 0.24685891 Acc: 1.00000000
iteration 1650 train loss: 0.24670509 Acc: 1.00000000
iteration 1700 train loss: 0.26312816 Acc: 0.87500000
iteration 1750 train loss: 0.25256070 Acc: 1.00000000
iteration 1800 train loss: 0.25421888 Acc: 1.00000000
iteration 1850 train loss: 0.25754306 Acc: 1.00000000
iteration 1900 train loss: 0.32713795 Acc: 0.50000000
iteration 1950 train loss: 0.27777210 Acc: 0.75000000
iteration 2000 train loss: 0.24501479 Acc: 1.00000000
iteration 2050 train loss: 0.27008790 Acc: 0.87500000
iteration 2100 train loss: 0.26602861 Acc: 0.87500000
iteration 2150 train loss: 0.25546247 Acc: 1.00000000
iteration 2200 train loss: 0.28063166 Acc: 0.87500000
iteration 2250 train loss: 0.30489236 Acc: 0.75000000
iteration 2300 train loss: 0.27697730 Acc: 0.87500000
iteration 2350 train loss: 0.26289210 Acc: 1.00000000
iteration 2400 train loss: 0.24350236 Acc: 1.00000000
iteration 2450 train loss: 0.25403297 Acc: 1.00000000
iteration 2500 train loss: 0.26979718 Acc: 0.87500000
iteration 2550 train loss: 0.25390059 Acc: 1.00000000
iteration 2600 train loss: 0.35591769 Acc: 0.75000000
iteration 2650 train loss: 0.25512072 Acc: 1.00000000
iteration 2700 train loss: 0.26611155 Acc: 0.87500000
iteration 2750 train loss: 0.25238574 Acc: 1.00000000
iteration 2800 train loss: 0.24810158 Acc: 1.00000000
iteration 2850 train loss: 0.25426948 Acc: 1.00000000
iteration 2900 train loss: 0.25635177 Acc: 0.87500000
iteration 2950 train loss: 0.24315535 Acc: 1.00000000
iteration 3000 train loss: 0.26949227 Acc: 0.87500000
iteration 3050 train loss: 0.25320300 Acc: 1.00000000
iteration 3100 train loss: 0.24772352 Acc: 1.00000000
iteration 3150 train loss: 0.28890145 Acc: 0.87500000
iteration 3200 train loss: 0.25013289 Acc: 1.00000000
iteration 3250 train loss: 0.24773534 Acc: 1.00000000
iteration 3300 train loss: 0.26755425 Acc: 0.87500000
iteration 3350 train loss: 0.25094765 Acc: 1.00000000
iteration 3400 train loss: 0.26437637 Acc: 0.87500000
iteration 3450 train loss: 0.24938636 Acc: 1.00000000
iteration 3500 train loss: 0.24657324 Acc: 1.00000000
iteration 3550 train loss: 0.27937195 Acc: 0.87500000
iteration 3600 train loss: 0.27162322 Acc: 0.87500000
iteration 3650 train loss: 0.24752869 Acc: 1.00000000
iteration 3700 train loss: 0.24646503 Acc: 1.00000000
iteration 3750 train loss: 0.24451339 Acc: 1.00000000
iteration 3800 train loss: 0.25369340 Acc: 1.00000000
iteration 3850 train loss: 0.24650173 Acc: 1.00000000
iteration 3900 train loss: 0.26068342 Acc: 1.00000000
iteration 3950 train loss: 0.24407730 Acc: 1.00000000
iteration 4000 train loss: 0.24272367 Acc: 1.00000000
iteration 4050 train loss: 0.24479546 Acc: 1.00000000
iteration 4100 train loss: 0.27275443 Acc: 0.87500000
iteration 4150 train loss: 0.24599013 Acc: 1.00000000
iteration 4200 train loss: 0.28989589 Acc: 0.87500000
iteration 4250 train loss: 0.25181374 Acc: 1.00000000
iteration 4300 train loss: 0.26326153 Acc: 1.00000000
iteration 4350 train loss: 0.25240299 Acc: 1.00000000
iteration 4400 train loss: 0.26954269 Acc: 0.87500000
iteration 4450 train loss: 0.26051468 Acc: 1.00000000
iteration 4500 train loss: 0.29727077 Acc: 0.75000000
iteration 4550 train loss: 0.24695392 Acc: 1.00000000
iteration 4600 train loss: 0.25804850 Acc: 0.87500000
iteration 4650 train loss: 0.24395651 Acc: 1.00000000
iteration 4700 train loss: 0.24578516 Acc: 1.00000000
iteration 4750 train loss: 0.26542896 Acc: 0.87500000
iteration 4800 train loss: 0.24463272 Acc: 1.00000000
iteration 4850 train loss: 0.24544533 Acc: 1.00000000
iteration 4900 train loss: 0.25212306 Acc: 1.00000000
iteration 4950 train loss: 0.24548344 Acc: 1.00000000
iteration 5000 train loss: 0.24320669 Acc: 1.00000000
iteration 5050 train loss: 0.25297889 Acc: 1.00000000
iteration 5100 train loss: 0.24521172 Acc: 1.00000000
iteration 5150 train loss: 0.25669003 Acc: 1.00000000
iteration 5200 train loss: 0.25149447 Acc: 1.00000000
iteration 5250 train loss: 0.24719161 Acc: 1.00000000
iteration 5300 train loss: 0.24713559 Acc: 1.00000000
iteration 5350 train loss: 0.24778879 Acc: 1.00000000
iteration 5400 train loss: 0.28080919 Acc: 0.87500000
iteration 5450 train loss: 0.24243949 Acc: 1.00000000
iteration 5500 train loss: 0.24283658 Acc: 1.00000000
iteration 5550 train loss: 0.41141990 Acc: 0.87500000
iteration 5600 train loss: 0.28461254 Acc: 0.75000000
iteration 5650 train loss: 0.24806853 Acc: 1.00000000
iteration 5700 train loss: 0.24449158 Acc: 1.00000000
iteration 5750 train loss: 0.25301534 Acc: 1.00000000
iteration 5800 train loss: 0.25113949 Acc: 1.00000000
iteration 5850 train loss: 0.24792060 Acc: 1.00000000
iteration 5900 train loss: 0.27267611 Acc: 0.87500000
iteration 5950 train loss: 0.24695283 Acc: 1.00000000
iteration 6000 train loss: 0.32446998 Acc: 0.75000000
iteration 6050 train loss: 0.24487072 Acc: 1.00000000
iteration 6100 train loss: 0.29751500 Acc: 0.87500000
iteration 6150 train loss: 0.26069069 Acc: 0.87500000
iteration 6200 train loss: 0.24506791 Acc: 1.00000000
iteration 6250 train loss: 0.29278678 Acc: 0.87500000
iteration 6300 train loss: 0.24746253 Acc: 1.00000000
iteration 6350 train loss: 0.24597523 Acc: 1.00000000
iteration 6400 train loss: 0.24334672 Acc: 1.00000000
iteration 6450 train loss: 0.25863177 Acc: 0.87500000
iteration 6500 train loss: 0.24366060 Acc: 1.00000000
iteration 6550 train loss: 0.24670623 Acc: 1.00000000
iteration 6600 train loss: 0.24685226 Acc: 1.00000000
iteration 6650 train loss: 0.24699332 Acc: 1.00000000
iteration 6700 train loss: 0.24461246 Acc: 1.00000000
iteration 6750 train loss: 0.28238893 Acc: 0.87500000
iteration 6800 train loss: 0.24786897 Acc: 1.00000000
iteration 6850 train loss: 0.25793034 Acc: 0.87500000
iteration 6900 train loss: 0.24794620 Acc: 1.00000000
iteration 6950 train loss: 0.24464558 Acc: 1.00000000
iteration 7000 train loss: 0.25327438 Acc: 1.00000000
iteration 7050 train loss: 0.26923016 Acc: 0.87500000
iteration 7100 train loss: 0.26052451 Acc: 0.87500000
iteration 7150 train loss: 0.25150433 Acc: 1.00000000
iteration 7200 train loss: 0.26510015 Acc: 0.87500000
iteration 7250 train loss: 0.27951425 Acc: 0.87500000
iteration 7300 train loss: 0.24680838 Acc: 1.00000000
iteration 7350 train loss: 0.28054884 Acc: 0.87500000
iteration 7400 train loss: 0.24604103 Acc: 1.00000000
iteration 7450 train loss: 0.24452047 Acc: 1.00000000
iteration 7500 train loss: 0.24715246 Acc: 1.00000000
iteration 7550 train loss: 0.30597118 Acc: 0.87500000
iteration 7600 train loss: 0.26034173 Acc: 0.87500000
iteration 7650 train loss: 0.24824992 Acc: 1.00000000
iteration 7700 train loss: 0.24838792 Acc: 1.00000000
iteration 7750 train loss: 0.26021844 Acc: 0.87500000
iteration 7800 train loss: 0.24677996 Acc: 1.00000000
iteration 7850 train loss: 0.24582963 Acc: 1.00000000
iteration 7900 train loss: 0.25459951 Acc: 1.00000000
iteration 7950 train loss: 0.24677293 Acc: 1.00000000
iteration 8000 train loss: 0.24242559 Acc: 1.00000000
iteration 8050 train loss: 0.24369031 Acc: 1.00000000
iteration 8100 train loss: 0.24973181 Acc: 1.00000000
iteration 8150 train loss: 0.27313498 Acc: 0.75000000
iteration 8200 train loss: 0.24295849 Acc: 1.00000000
iteration 8250 train loss: 0.24593195 Acc: 1.00000000
iteration 8300 train loss: 0.24421094 Acc: 1.00000000
iteration 8350 train loss: 0.27326688 Acc: 0.87500000
iteration 8400 train loss: 0.24703115 Acc: 1.00000000
iteration 8450 train loss: 0.28576577 Acc: 0.87500000
iteration 8500 train loss: 0.24695086 Acc: 1.00000000
iteration 8550 train loss: 0.24804232 Acc: 1.00000000
iteration 8600 train loss: 0.24333902 Acc: 1.00000000
iteration 8650 train loss: 0.24183212 Acc: 1.00000000
iteration 8700 train loss: 0.33919558 Acc: 0.87500000
iteration 8750 train loss: 0.24152228 Acc: 1.00000000
epoch train loss: nan Acc: 0.93895888
 10%|█         | 1/10 [05:14<47:12, 314.72s/it]epoch val loss: 0.02345355 Acc: 0.92837942
Epoch 2/10
----------
iteration 8800 train loss: 0.24402079 Acc: 1.00000000
iteration 8850 train loss: 0.24261039 Acc: 1.00000000
iteration 8900 train loss: 0.24288197 Acc: 1.00000000
iteration 8950 train loss: 0.30928522 Acc: 0.75000000
iteration 9000 train loss: 0.26126522 Acc: 0.87500000
iteration 9050 train loss: 0.24416643 Acc: 1.00000000
iteration 9100 train loss: 0.24729088 Acc: 1.00000000
iteration 9150 train loss: 0.24051638 Acc: 1.00000000
iteration 9200 train loss: 0.24325219 Acc: 1.00000000
iteration 9250 train loss: 0.24345358 Acc: 1.00000000
iteration 9300 train loss: 0.25748029 Acc: 1.00000000
iteration 9350 train loss: 0.25324166 Acc: 1.00000000
iteration 9400 train loss: 0.24973948 Acc: 1.00000000
iteration 9450 train loss: 0.26574677 Acc: 0.87500000
iteration 9500 train loss: 0.24576046 Acc: 1.00000000
iteration 9550 train loss: 0.27121580 Acc: 0.87500000
iteration 9600 train loss: 0.25810573 Acc: 0.87500000
iteration 9650 train loss: 0.26125082 Acc: 0.87500000
iteration 9700 train loss: 0.26863238 Acc: 0.87500000
iteration 9750 train loss: 0.25948107 Acc: 0.87500000
iteration 9800 train loss: 0.28616321 Acc: 0.75000000
iteration 9850 train loss: 0.29631242 Acc: 0.87500000
iteration 9900 train loss: 0.24609870 Acc: 1.00000000
iteration 9950 train loss: 0.24367942 Acc: 1.00000000
iteration 10000 train loss: 0.25343257 Acc: 1.00000000
iteration 10050 train loss: 0.24283876 Acc: 1.00000000
iteration 10100 train loss: 0.25760484 Acc: 0.87500000
iteration 10150 train loss: 0.25252163 Acc: 1.00000000
iteration 10200 train loss: 0.24681392 Acc: 1.00000000
iteration 10250 train loss: 0.24409541 Acc: 1.00000000
iteration 10300 train loss: 0.24825576 Acc: 1.00000000
iteration 10350 train loss: 0.25181979 Acc: 1.00000000
iteration 10400 train loss: 0.25064176 Acc: 1.00000000
iteration 10450 train loss: 0.28656486 Acc: 0.87500000
iteration 10500 train loss: 0.24380790 Acc: 1.00000000
iteration 10550 train loss: 0.25183755 Acc: 1.00000000
iteration 10600 train loss: 0.24479596 Acc: 1.00000000
iteration 10650 train loss: 0.24494551 Acc: 1.00000000
iteration 10700 train loss: 0.24551795 Acc: 1.00000000
iteration 10750 train loss: 0.24330293 Acc: 1.00000000
iteration 10800 train loss: 0.24304259 Acc: 1.00000000
iteration 10850 train loss: 0.26750582 Acc: 0.87500000
iteration 10900 train loss: 0.25739956 Acc: 1.00000000
iteration 10950 train loss: 0.27685004 Acc: 0.87500000
iteration 11000 train loss: 0.24476658 Acc: 1.00000000
iteration 11050 train loss: 0.24603252 Acc: 1.00000000
iteration 11100 train loss: 0.24505341 Acc: 1.00000000
iteration 11150 train loss: 0.24553469 Acc: 1.00000000
iteration 11200 train loss: 0.24331361 Acc: 1.00000000
iteration 11250 train loss: 0.24345994 Acc: 1.00000000
iteration 11300 train loss: 0.25756404 Acc: 1.00000000
iteration 11350 train loss: 0.24903782 Acc: 1.00000000
iteration 11400 train loss: 0.24628796 Acc: 1.00000000
iteration 11450 train loss: 0.25390878 Acc: 1.00000000
iteration 11500 train loss: 0.25214821 Acc: 1.00000000
iteration 11550 train loss: 0.24769183 Acc: 1.00000000
iteration 11600 train loss: 0.25309071 Acc: 1.00000000
iteration 11650 train loss: 0.24559079 Acc: 1.00000000
iteration 11700 train loss: 0.32489741 Acc: 0.75000000
iteration 11750 train loss: 0.24353360 Acc: 1.00000000
iteration 11800 train loss: 0.24228042 Acc: 1.00000000
iteration 11850 train loss: 0.24431746 Acc: 1.00000000
iteration 11900 train loss: 0.25241843 Acc: 1.00000000
iteration 11950 train loss: 0.25237942 Acc: 1.00000000
iteration 12000 train loss: 0.24388148 Acc: 1.00000000
iteration 12050 train loss: 0.26786029 Acc: 0.87500000
iteration 12100 train loss: 0.24682955 Acc: 1.00000000
iteration 12150 train loss: 0.25218263 Acc: 1.00000000
iteration 12200 train loss: 0.26679167 Acc: 0.87500000
iteration 12250 train loss: 0.25202289 Acc: 1.00000000
iteration 12300 train loss: 0.25436169 Acc: 0.87500000
iteration 12350 train loss: 0.24880552 Acc: 1.00000000
iteration 12400 train loss: 0.24600738 Acc: 1.00000000
iteration 12450 train loss: 0.25593373 Acc: 0.87500000
iteration 12500 train loss: 0.25969562 Acc: 0.87500000
iteration 12550 train loss: 0.29923403 Acc: 0.75000000
iteration 12600 train loss: 0.26720133 Acc: 0.87500000
iteration 12650 train loss: 0.27471125 Acc: 0.87500000
iteration 12700 train loss: 0.24486355 Acc: 1.00000000
iteration 12750 train loss: 0.26471797 Acc: 0.87500000
iteration 12800 train loss: 0.32108805 Acc: 0.87500000
iteration 12850 train loss: 0.26196510 Acc: 0.87500000
iteration 12900 train loss: 0.37712318 Acc: 0.75000000
iteration 12950 train loss: 0.25770280 Acc: 0.87500000
iteration 13000 train loss: 0.24427596 Acc: 1.00000000
iteration 13050 train loss: 0.24400888 Acc: 1.00000000
iteration 13100 train loss: 0.24133304 Acc: 1.00000000
iteration 13150 train loss: 0.24551703 Acc: 1.00000000
iteration 13200 train loss: 0.24363588 Acc: 1.00000000
iteration 13250 train loss: 0.25485808 Acc: 0.87500000
iteration 13300 train loss: 0.24830540 Acc: 1.00000000
iteration 13350 train loss: 0.25600663 Acc: 1.00000000
iteration 13400 train loss: 0.24308373 Acc: 1.00000000
iteration 13450 train loss: 0.24209447 Acc: 1.00000000
iteration 13500 train loss: 0.25277555 Acc: 1.00000000
iteration 13550 train loss: 0.25541741 Acc: 1.00000000
iteration 13600 train loss: 0.24811471 Acc: 1.00000000
iteration 13650 train loss: 0.24896911 Acc: 1.00000000
iteration 13700 train loss: 0.24272016 Acc: 1.00000000
iteration 13750 train loss: 0.24932516 Acc: 1.00000000
iteration 13800 train loss: 0.41462386 Acc: 0.75000000
iteration 13850 train loss: 0.25461683 Acc: 1.00000000
iteration 13900 train loss: 0.26098213 Acc: 0.87500000
iteration 13950 train loss: 0.26665220 Acc: 0.87500000
iteration 14000 train loss: 0.25712031 Acc: 0.87500000
iteration 14050 train loss: 0.24336341 Acc: 1.00000000
iteration 14100 train loss: 0.32761282 Acc: 0.62500000
iteration 14150 train loss: 0.24420249 Acc: 1.00000000
iteration 14200 train loss: 0.24196777 Acc: 1.00000000
iteration 14250 train loss: 0.25380623 Acc: 0.87500000
iteration 14300 train loss: 0.24366577 Acc: 1.00000000
iteration 14350 train loss: 0.24631059 Acc: 1.00000000
iteration 14400 train loss: 0.24496110 Acc: 1.00000000
iteration 14450 train loss: 0.25626668 Acc: 0.87500000
iteration 14500 train loss: 0.24406940 Acc: 1.00000000
iteration 14550 train loss: 0.24420246 Acc: 1.00000000
iteration 14600 train loss: 0.24460064 Acc: 1.00000000
iteration 14650 train loss: 0.24689750 Acc: 1.00000000
iteration 14700 train loss: 0.24189827 Acc: 1.00000000
iteration 14750 train loss: 0.24218224 Acc: 1.00000000
iteration 14800 train loss: 0.24461471 Acc: 1.00000000
iteration 14850 train loss: 0.24409135 Acc: 1.00000000
iteration 14900 train loss: 0.26335013 Acc: 0.87500000
iteration 14950 train loss: 0.24690124 Acc: 1.00000000
iteration 15000 train loss: 0.24497065 Acc: 1.00000000
iteration 15050 train loss: 0.25674736 Acc: 0.87500000
iteration 15100 train loss: 0.25461313 Acc: 1.00000000
iteration 15150 train loss: 0.24637638 Acc: 1.00000000
iteration 15200 train loss: 0.24380538 Acc: 1.00000000
iteration 15250 train loss: 0.25040808 Acc: 1.00000000
iteration 15300 train loss: 0.24373916 Acc: 1.00000000
iteration 15350 train loss: 0.24420758 Acc: 1.00000000
iteration 15400 train loss: 0.31938198 Acc: 0.87500000
iteration 15450 train loss: 0.25551426 Acc: 0.87500000
iteration 15500 train loss: 0.26764962 Acc: 0.87500000
iteration 15550 train loss: 0.24529070 Acc: 1.00000000
iteration 15600 train loss: 0.24460234 Acc: 1.00000000
iteration 15650 train loss: 0.25852466 Acc: 0.87500000
iteration 15700 train loss: 0.24614395 Acc: 1.00000000
iteration 15750 train loss: 0.24732131 Acc: 1.00000000
iteration 15800 train loss: 0.25417602 Acc: 1.00000000
iteration 15850 train loss: 0.24967946 Acc: 1.00000000
iteration 15900 train loss: 0.24553791 Acc: 1.00000000
iteration 15950 train loss: 0.30801690 Acc: 0.87500000
iteration 16000 train loss: 0.24484067 Acc: 1.00000000
iteration 16050 train loss: 0.25417846 Acc: 0.87500000
iteration 16100 train loss: 0.25069475 Acc: 1.00000000
iteration 16150 train loss: 0.26338243 Acc: 0.87500000
iteration 16200 train loss: 0.24484095 Acc: 1.00000000
iteration 16250 train loss: 0.24298495 Acc: 1.00000000
iteration 16300 train loss: 0.23994587 Acc: 1.00000000
iteration 16350 train loss: 0.24828428 Acc: 1.00000000
iteration 16400 train loss: 0.24816023 Acc: 1.00000000
iteration 16450 train loss: 0.24434854 Acc: 1.00000000
iteration 16500 train loss: 0.26084441 Acc: 0.87500000
iteration 16550 train loss: 0.24279246 Acc: 1.00000000
iteration 16600 train loss: 0.24765818 Acc: 1.00000000
iteration 16650 train loss: 0.24694720 Acc: 1.00000000
iteration 16700 train loss: 0.25498909 Acc: 1.00000000
iteration 16750 train loss: 0.24336520 Acc: 1.00000000
iteration 16800 train loss: 0.26134732 Acc: 0.87500000
iteration 16850 train loss: 0.25310388 Acc: 1.00000000
iteration 16900 train loss: 0.24426711 Acc: 1.00000000
iteration 16950 train loss: 0.24406043 Acc: 1.00000000
iteration 17000 train loss: 0.26107478 Acc: 0.87500000
iteration 17050 train loss: 0.24933277 Acc: 1.00000000
iteration 17100 train loss: 0.24644175 Acc: 1.00000000
iteration 17150 train loss: 0.24513832 Acc: 1.00000000
iteration 17200 train loss: 0.24422306 Acc: 1.00000000
iteration 17250 train loss: 0.24312128 Acc: 1.00000000
iteration 17300 train loss: 0.24410729 Acc: 1.00000000
iteration 17350 train loss: 0.26577342 Acc: 0.75000000
iteration 17400 train loss: 0.24739330 Acc: 1.00000000
iteration 17450 train loss: 0.24537967 Acc: 1.00000000
iteration 17500 train loss: 0.25670186 Acc: 0.87500000
epoch train loss: 0.25427322 Acc: 0.96587241
 20%|██        | 2/10 [10:34<42:23, 317.93s/it]epoch val loss: 0.01248337 Acc: 0.96236366
Epoch 3/10
----------
iteration 17550 train loss: 0.24569792 Acc: 1.00000000
iteration 17600 train loss: 0.24308933 Acc: 1.00000000
iteration 17650 train loss: 0.24454747 Acc: 1.00000000
iteration 17700 train loss: 0.24304695 Acc: 1.00000000
iteration 17750 train loss: 0.24486519 Acc: 1.00000000
iteration 17800 train loss: 0.24474764 Acc: 1.00000000
iteration 17850 train loss: 0.24493381 Acc: 1.00000000
iteration 17900 train loss: 0.24361059 Acc: 1.00000000
iteration 17950 train loss: 0.24168888 Acc: 1.00000000
iteration 18000 train loss: 0.27125928 Acc: 0.87500000
iteration 18050 train loss: 0.24375679 Acc: 1.00000000
iteration 18100 train loss: 0.24780834 Acc: 1.00000000
iteration 18150 train loss: 0.24352004 Acc: 1.00000000
iteration 18200 train loss: 0.24825248 Acc: 1.00000000
iteration 18250 train loss: 0.24325450 Acc: 1.00000000
iteration 18300 train loss: 0.24331963 Acc: 1.00000000
iteration 18350 train loss: 0.32259515 Acc: 0.87500000
iteration 18400 train loss: 0.24730158 Acc: 1.00000000
iteration 18450 train loss: 0.24454129 Acc: 1.00000000
iteration 18500 train loss: 0.24566430 Acc: 1.00000000
iteration 18550 train loss: 0.27524954 Acc: 0.75000000
iteration 18600 train loss: 0.24573570 Acc: 1.00000000
iteration 18650 train loss: 0.24356313 Acc: 1.00000000
iteration 18700 train loss: 0.24514832 Acc: 1.00000000
iteration 18750 train loss: 0.24192750 Acc: 1.00000000
iteration 18800 train loss: 0.24363966 Acc: 1.00000000
iteration 18850 train loss: 0.24193256 Acc: 1.00000000
iteration 18900 train loss: 0.24332350 Acc: 1.00000000
iteration 18950 train loss: 0.24321176 Acc: 1.00000000
iteration 19000 train loss: 0.27758920 Acc: 0.75000000
iteration 19050 train loss: 0.24647930 Acc: 1.00000000
iteration 19100 train loss: 0.24993825 Acc: 1.00000000
iteration 19150 train loss: 0.28191188 Acc: 0.75000000
iteration 19200 train loss: 0.24309000 Acc: 1.00000000
iteration 19250 train loss: 0.24658912 Acc: 1.00000000
iteration 19300 train loss: 0.30282655 Acc: 0.87500000
iteration 19350 train loss: 0.24349493 Acc: 1.00000000
iteration 19400 train loss: 0.24271896 Acc: 1.00000000
iteration 19450 train loss: 0.24256240 Acc: 1.00000000
iteration 19500 train loss: 0.24267283 Acc: 1.00000000
iteration 19550 train loss: 0.24391121 Acc: 1.00000000
iteration 19600 train loss: 0.24270909 Acc: 1.00000000
iteration 19650 train loss: 0.24405502 Acc: 1.00000000
iteration 19700 train loss: 0.24293420 Acc: 1.00000000
iteration 19750 train loss: 0.24469025 Acc: 1.00000000
iteration 19800 train loss: 0.25021023 Acc: 1.00000000
iteration 19850 train loss: 0.25153413 Acc: 1.00000000
iteration 19900 train loss: 0.24001376 Acc: 1.00000000
iteration 19950 train loss: 0.28514108 Acc: 0.87500000
iteration 20000 train loss: 0.28833121 Acc: 0.87500000
iteration 20050 train loss: 0.24381767 Acc: 1.00000000
iteration 20100 train loss: 0.24973299 Acc: 1.00000000
iteration 20150 train loss: 0.27245522 Acc: 0.87500000
iteration 20200 train loss: 0.25073758 Acc: 1.00000000
iteration 20250 train loss: 0.24412283 Acc: 1.00000000
iteration 20300 train loss: 0.25143158 Acc: 1.00000000
iteration 20350 train loss: 0.24293780 Acc: 1.00000000
iteration 20400 train loss: 0.24554071 Acc: 1.00000000
iteration 20450 train loss: 0.24349853 Acc: 1.00000000
iteration 20500 train loss: 0.25630566 Acc: 0.87500000
iteration 20550 train loss: 0.25921357 Acc: 0.87500000
iteration 20600 train loss: 0.25150543 Acc: 1.00000000
iteration 20650 train loss: 0.24141814 Acc: 1.00000000
iteration 20700 train loss: 0.28305629 Acc: 0.87500000
iteration 20750 train loss: 0.24471618 Acc: 1.00000000
iteration 20800 train loss: 0.25516537 Acc: 1.00000000
iteration 20850 train loss: 0.24386942 Acc: 1.00000000
iteration 20900 train loss: 0.25439841 Acc: 1.00000000
iteration 20950 train loss: 0.24379577 Acc: 1.00000000
iteration 21000 train loss: 0.24626090 Acc: 1.00000000
iteration 21050 train loss: 0.24496582 Acc: 1.00000000
iteration 21100 train loss: 0.24283271 Acc: 1.00000000
iteration 21150 train loss: 0.24278268 Acc: 1.00000000
iteration 21200 train loss: 0.24340813 Acc: 1.00000000
iteration 21250 train loss: 0.25695780 Acc: 0.87500000
iteration 21300 train loss: 0.24633394 Acc: 1.00000000
iteration 21350 train loss: 0.24752247 Acc: 1.00000000
iteration 21400 train loss: 0.24799211 Acc: 1.00000000
iteration 21450 train loss: 0.25875932 Acc: 0.87500000
iteration 21500 train loss: 0.29701662 Acc: 0.87500000
iteration 21550 train loss: 0.27366483 Acc: 0.87500000
iteration 21600 train loss: 0.24525453 Acc: 1.00000000
iteration 21650 train loss: 0.24653751 Acc: 1.00000000
iteration 21700 train loss: 0.24570714 Acc: 1.00000000
iteration 21750 train loss: 0.24638095 Acc: 1.00000000
iteration 21800 train loss: 0.24556944 Acc: 1.00000000
iteration 21850 train loss: 0.24500963 Acc: 1.00000000
iteration 21900 train loss: 0.24642003 Acc: 1.00000000
iteration 21950 train loss: 0.24681640 Acc: 1.00000000
iteration 22000 train loss: 0.34214973 Acc: 0.87500000
iteration 22050 train loss: 0.24807373 Acc: 1.00000000
iteration 22100 train loss: 0.24290323 Acc: 1.00000000
iteration 22150 train loss: 0.25466418 Acc: 1.00000000
iteration 22200 train loss: 0.24541786 Acc: 1.00000000
iteration 22250 train loss: 0.24758421 Acc: 1.00000000
iteration 22300 train loss: 0.24788131 Acc: 1.00000000
iteration 22350 train loss: 0.24217956 Acc: 1.00000000
iteration 22400 train loss: 0.26998958 Acc: 0.87500000
iteration 22450 train loss: 0.24445099 Acc: 1.00000000
iteration 22500 train loss: 0.24376437 Acc: 1.00000000
iteration 22550 train loss: 0.25318998 Acc: 1.00000000
iteration 22600 train loss: 0.24295805 Acc: 1.00000000
iteration 22650 train loss: 0.24622944 Acc: 1.00000000
iteration 22700 train loss: 0.24490723 Acc: 1.00000000
iteration 22750 train loss: 0.26217732 Acc: 0.87500000
iteration 22800 train loss: 0.24438442 Acc: 1.00000000
iteration 22850 train loss: 0.24000886 Acc: 1.00000000
iteration 22900 train loss: 0.26245821 Acc: 0.87500000
iteration 22950 train loss: 0.24417520 Acc: 1.00000000
iteration 23000 train loss: 0.24958289 Acc: 1.00000000
iteration 23050 train loss: 0.24765535 Acc: 1.00000000
iteration 23100 train loss: 0.24447338 Acc: 1.00000000
iteration 23150 train loss: 0.24386729 Acc: 1.00000000
iteration 23200 train loss: 0.24678399 Acc: 1.00000000
iteration 23250 train loss: 0.24774392 Acc: 1.00000000
iteration 23300 train loss: 0.26263839 Acc: 0.87500000
iteration 23350 train loss: 0.24384451 Acc: 1.00000000
iteration 23400 train loss: 0.24332163 Acc: 1.00000000
iteration 23450 train loss: 0.25868782 Acc: 0.87500000
iteration 23500 train loss: 0.24556890 Acc: 1.00000000
iteration 23550 train loss: 0.25639874 Acc: 0.87500000
iteration 23600 train loss: 0.24313881 Acc: 1.00000000
iteration 23650 train loss: 0.24290250 Acc: 1.00000000
iteration 23700 train loss: 0.25146586 Acc: 1.00000000
iteration 23750 train loss: 0.25664908 Acc: 0.87500000
iteration 23800 train loss: 0.25017679 Acc: 1.00000000
iteration 23850 train loss: 0.35206378 Acc: 0.75000000
iteration 23900 train loss: 0.24242651 Acc: 1.00000000
iteration 23950 train loss: 0.24220824 Acc: 1.00000000
iteration 24000 train loss: 0.25725332 Acc: 0.87500000
iteration 24050 train loss: 0.24531099 Acc: 1.00000000
iteration 24100 train loss: 0.28315848 Acc: 0.87500000
iteration 24150 train loss: 0.26270318 Acc: 0.87500000
iteration 24200 train loss: 0.25827578 Acc: 0.87500000
iteration 24250 train loss: 0.24253619 Acc: 1.00000000
iteration 24300 train loss: 0.24277048 Acc: 1.00000000
iteration 24350 train loss: 0.24497646 Acc: 1.00000000
iteration 24400 train loss: 0.25940183 Acc: 0.87500000
iteration 24450 train loss: 0.24218933 Acc: 1.00000000
iteration 24500 train loss: 0.26210523 Acc: 1.00000000
iteration 24550 train loss: 0.29072762 Acc: 0.87500000
iteration 24600 train loss: 0.25685677 Acc: 0.87500000
iteration 24650 train loss: 0.24741143 Acc: 1.00000000
iteration 24700 train loss: 0.24413548 Acc: 1.00000000
iteration 24750 train loss: 0.25057268 Acc: 1.00000000
iteration 24800 train loss: 0.24837869 Acc: 1.00000000
iteration 24850 train loss: 0.24377999 Acc: 1.00000000
iteration 24900 train loss: 0.24852854 Acc: 1.00000000
iteration 24950 train loss: 0.27347022 Acc: 0.87500000
iteration 25000 train loss: 0.27430278 Acc: 0.87500000
iteration 25050 train loss: 0.24220817 Acc: 1.00000000
iteration 25100 train loss: 0.24468619 Acc: 1.00000000
iteration 25150 train loss: 0.28513616 Acc: 0.87500000
iteration 25200 train loss: 0.25108230 Acc: 1.00000000
iteration 25250 train loss: 0.24292777 Acc: 1.00000000
iteration 25300 train loss: 0.24460019 Acc: 1.00000000
iteration 25350 train loss: 0.24336271 Acc: 1.00000000
iteration 25400 train loss: 0.24606536 Acc: 1.00000000
iteration 25450 train loss: 0.24315225 Acc: 1.00000000
iteration 25500 train loss: 0.25585911 Acc: 1.00000000
iteration 25550 train loss: 0.27589646 Acc: 0.87500000
iteration 25600 train loss: 0.24372040 Acc: 1.00000000
iteration 25650 train loss: 0.24393220 Acc: 1.00000000
iteration 25700 train loss: 0.24510714 Acc: 1.00000000
iteration 25750 train loss: 0.24223253 Acc: 1.00000000
iteration 25800 train loss: 0.24670914 Acc: 1.00000000
iteration 25850 train loss: 0.25811204 Acc: 0.87500000
iteration 25900 train loss: 0.25782153 Acc: 0.87500000
iteration 25950 train loss: 0.25206122 Acc: 1.00000000
iteration 26000 train loss: 0.24600789 Acc: 1.00000000
iteration 26050 train loss: 0.24361326 Acc: 1.00000000
iteration 26100 train loss: 0.24482584 Acc: 1.00000000
iteration 26150 train loss: 0.27619913 Acc: 0.87500000
iteration 26200 train loss: 0.26425564 Acc: 0.87500000
iteration 26250 train loss: 0.24535389 Acc: 1.00000000
epoch train loss: 0.25169561 Acc: 0.97348648
 30%|███       | 3/10 [15:50<36:58, 316.98s/it]epoch val loss: 0.01578048 Acc: 0.95485669
Epoch 4/10
----------
iteration 26300 train loss: 0.24470015 Acc: 1.00000000
iteration 26350 train loss: 0.24559523 Acc: 1.00000000
iteration 26400 train loss: 0.25007823 Acc: 1.00000000
iteration 26450 train loss: 0.24422301 Acc: 1.00000000
iteration 26500 train loss: 0.32684368 Acc: 0.87500000
iteration 26550 train loss: 0.27545014 Acc: 0.87500000
iteration 26600 train loss: 0.26152876 Acc: 0.87500000
iteration 26650 train loss: 0.24360621 Acc: 1.00000000
iteration 26700 train loss: 0.24468929 Acc: 1.00000000
iteration 26750 train loss: 0.24371520 Acc: 1.00000000
iteration 26800 train loss: 0.25688049 Acc: 0.87500000
iteration 26850 train loss: 0.24666524 Acc: 1.00000000
iteration 26900 train loss: 0.24360938 Acc: 1.00000000
iteration 26950 train loss: 0.25664544 Acc: 0.87500000
iteration 27000 train loss: 0.24396326 Acc: 1.00000000
iteration 27050 train loss: 0.24339804 Acc: 1.00000000
iteration 27100 train loss: 0.24579602 Acc: 1.00000000
iteration 27150 train loss: 0.24356726 Acc: 1.00000000
iteration 27200 train loss: 0.24308681 Acc: 1.00000000
iteration 27250 train loss: 0.26279324 Acc: 0.87500000
iteration 27300 train loss: 0.24433111 Acc: 1.00000000
iteration 27350 train loss: 0.24210484 Acc: 1.00000000
iteration 27400 train loss: 0.24324167 Acc: 1.00000000
iteration 27450 train loss: 0.24758433 Acc: 1.00000000
iteration 27500 train loss: 0.24378000 Acc: 1.00000000
iteration 27550 train loss: 0.24511242 Acc: 1.00000000
iteration 27600 train loss: 0.24144511 Acc: 1.00000000
iteration 27650 train loss: 0.24306154 Acc: 1.00000000
iteration 27700 train loss: 0.24552011 Acc: 1.00000000
iteration 27750 train loss: 0.24298052 Acc: 1.00000000
iteration 27800 train loss: 0.24289340 Acc: 1.00000000
iteration 27850 train loss: 0.24396984 Acc: 1.00000000
iteration 27900 train loss: 0.25378463 Acc: 0.87500000
iteration 27950 train loss: 0.24250163 Acc: 1.00000000
iteration 28000 train loss: 0.24278376 Acc: 1.00000000
iteration 28050 train loss: 0.33250055 Acc: 0.87500000
iteration 28100 train loss: 0.24254458 Acc: 1.00000000
iteration 28150 train loss: 0.24350749 Acc: 1.00000000
iteration 28200 train loss: 0.24472718 Acc: 1.00000000
iteration 28250 train loss: 0.24207287 Acc: 1.00000000
iteration 28300 train loss: 0.24333106 Acc: 1.00000000
iteration 28350 train loss: 0.24470605 Acc: 1.00000000
iteration 28400 train loss: 0.27681261 Acc: 0.87500000
iteration 28450 train loss: 0.24405928 Acc: 1.00000000
iteration 28500 train loss: 0.26054448 Acc: 0.87500000
iteration 28550 train loss: 0.24291803 Acc: 1.00000000
iteration 28600 train loss: 0.24285239 Acc: 1.00000000
iteration 28650 train loss: 0.24325065 Acc: 1.00000000
iteration 28700 train loss: 0.24377024 Acc: 1.00000000
iteration 28750 train loss: 0.25063556 Acc: 1.00000000
iteration 28800 train loss: 0.24199268 Acc: 1.00000000
iteration 28850 train loss: 0.25313741 Acc: 1.00000000
iteration 28900 train loss: 0.25100574 Acc: 1.00000000
iteration 28950 train loss: 0.24403867 Acc: 1.00000000
iteration 29000 train loss: 0.24292655 Acc: 1.00000000
iteration 29050 train loss: 0.25210601 Acc: 1.00000000
iteration 29100 train loss: 0.24485831 Acc: 1.00000000
iteration 29150 train loss: 0.24421275 Acc: 1.00000000
iteration 29200 train loss: 0.24338290 Acc: 1.00000000
iteration 29250 train loss: 0.24311149 Acc: 1.00000000
iteration 29300 train loss: 0.24220508 Acc: 1.00000000
iteration 29350 train loss: 0.24483573 Acc: 1.00000000
iteration 29400 train loss: 0.32600552 Acc: 0.75000000
iteration 29450 train loss: 0.24326688 Acc: 1.00000000
iteration 29500 train loss: 0.24159522 Acc: 1.00000000
iteration 29550 train loss: 0.24495862 Acc: 1.00000000
iteration 29600 train loss: 0.24359903 Acc: 1.00000000
iteration 29650 train loss: 0.24378023 Acc: 1.00000000
iteration 29700 train loss: 0.25143480 Acc: 1.00000000
iteration 29750 train loss: 0.24248928 Acc: 1.00000000
iteration 29800 train loss: 0.24287412 Acc: 1.00000000
iteration 29850 train loss: 0.24438702 Acc: 1.00000000
iteration 29900 train loss: 0.24356595 Acc: 1.00000000
iteration 29950 train loss: 0.24329583 Acc: 1.00000000
iteration 30000 train loss: 0.24395865 Acc: 1.00000000
iteration 30050 train loss: 0.24916108 Acc: 1.00000000
iteration 30100 train loss: 0.25946394 Acc: 0.87500000
iteration 30150 train loss: 0.24535745 Acc: 1.00000000
iteration 30200 train loss: 0.24520487 Acc: 1.00000000
iteration 30250 train loss: 0.25021440 Acc: 1.00000000
iteration 30300 train loss: 0.26404136 Acc: 0.87500000
iteration 30350 train loss: 0.24397242 Acc: 1.00000000
iteration 30400 train loss: 0.24302746 Acc: 1.00000000
iteration 30450 train loss: 0.25577858 Acc: 1.00000000
iteration 30500 train loss: 0.24506317 Acc: 1.00000000
iteration 30550 train loss: 0.24524550 Acc: 1.00000000
iteration 30600 train loss: 0.24477915 Acc: 1.00000000
iteration 30650 train loss: 0.24227123 Acc: 1.00000000
iteration 30700 train loss: 0.24164586 Acc: 1.00000000
iteration 30750 train loss: 0.24391343 Acc: 1.00000000
iteration 30800 train loss: 0.24737655 Acc: 1.00000000
iteration 30850 train loss: 0.24888496 Acc: 1.00000000
iteration 30900 train loss: 0.24361485 Acc: 1.00000000
iteration 30950 train loss: 0.24304911 Acc: 1.00000000
iteration 31000 train loss: 0.24396841 Acc: 1.00000000
iteration 31050 train loss: 0.24294941 Acc: 1.00000000
iteration 31100 train loss: 0.24679260 Acc: 1.00000000
iteration 31150 train loss: 0.25342539 Acc: 1.00000000
iteration 31200 train loss: 0.24234098 Acc: 1.00000000
iteration 31250 train loss: 0.24391598 Acc: 1.00000000
iteration 31300 train loss: 0.24456671 Acc: 1.00000000
iteration 31350 train loss: 0.24667285 Acc: 1.00000000
iteration 31400 train loss: 0.24244100 Acc: 1.00000000
iteration 31450 train loss: 0.24279082 Acc: 1.00000000
iteration 31500 train loss: 0.24386539 Acc: 1.00000000
iteration 31550 train loss: 0.25881562 Acc: 0.87500000
iteration 31600 train loss: 0.24341562 Acc: 1.00000000
iteration 31650 train loss: 0.24312390 Acc: 1.00000000
iteration 31700 train loss: 0.24275206 Acc: 1.00000000
iteration 31750 train loss: 0.24278930 Acc: 1.00000000
iteration 31800 train loss: 0.25051567 Acc: 1.00000000
iteration 31850 train loss: 0.25173706 Acc: 1.00000000
iteration 31900 train loss: 0.24662429 Acc: 1.00000000
iteration 31950 train loss: 0.24288408 Acc: 1.00000000
iteration 32000 train loss: 0.24355145 Acc: 1.00000000
iteration 32050 train loss: 0.24651489 Acc: 1.00000000
iteration 32100 train loss: 0.25804335 Acc: 0.87500000
iteration 32150 train loss: 0.24402422 Acc: 1.00000000
iteration 32200 train loss: 0.26078528 Acc: 0.87500000
iteration 32250 train loss: 0.24301019 Acc: 1.00000000
iteration 32300 train loss: 0.24312344 Acc: 1.00000000
iteration 32350 train loss: 0.25136337 Acc: 1.00000000
iteration 32400 train loss: 0.24745217 Acc: 1.00000000
iteration 32450 train loss: 0.24381521 Acc: 1.00000000
iteration 32500 train loss: 0.25033969 Acc: 1.00000000
iteration 32550 train loss: 0.24365479 Acc: 1.00000000
iteration 32600 train loss: 0.27017650 Acc: 0.87500000
iteration 32650 train loss: 0.24319831 Acc: 1.00000000
iteration 32700 train loss: 0.25792471 Acc: 0.87500000
iteration 32750 train loss: 0.24402043 Acc: 1.00000000
iteration 32800 train loss: 0.24211265 Acc: 1.00000000
iteration 32850 train loss: 0.24575183 Acc: 1.00000000
iteration 32900 train loss: 0.24532709 Acc: 1.00000000
iteration 32950 train loss: 0.24610759 Acc: 1.00000000
iteration 33000 train loss: 0.24321541 Acc: 1.00000000
iteration 33050 train loss: 0.24504940 Acc: 1.00000000
iteration 33100 train loss: 0.24335462 Acc: 1.00000000
iteration 33150 train loss: 0.24298166 Acc: 1.00000000
iteration 33200 train loss: 0.24219541 Acc: 1.00000000
iteration 33250 train loss: 0.24413209 Acc: 1.00000000
iteration 33300 train loss: 0.24336438 Acc: 1.00000000
iteration 33350 train loss: 0.24200350 Acc: 1.00000000
iteration 33400 train loss: 0.24596705 Acc: 1.00000000
iteration 33450 train loss: 0.24319033 Acc: 1.00000000
iteration 33500 train loss: 0.24156033 Acc: 1.00000000
iteration 33550 train loss: 0.24427134 Acc: 1.00000000
iteration 33600 train loss: 0.24581963 Acc: 1.00000000
iteration 33650 train loss: 0.33971077 Acc: 0.87500000
iteration 33700 train loss: 0.24311194 Acc: 1.00000000
iteration 33750 train loss: 0.24567060 Acc: 1.00000000
iteration 33800 train loss: 0.24232197 Acc: 1.00000000
iteration 33850 train loss: 0.24995898 Acc: 1.00000000
iteration 33900 train loss: 0.24354228 Acc: 1.00000000
iteration 33950 train loss: 0.24455720 Acc: 1.00000000
iteration 34000 train loss: 0.24567491 Acc: 1.00000000
iteration 34050 train loss: 0.25082722 Acc: 1.00000000
iteration 34100 train loss: 0.24324313 Acc: 1.00000000
iteration 34150 train loss: 0.24359579 Acc: 1.00000000
iteration 34200 train loss: 0.25165308 Acc: 1.00000000
iteration 34250 train loss: 0.24715546 Acc: 1.00000000
iteration 34300 train loss: 0.25397533 Acc: 1.00000000
iteration 34350 train loss: 0.24666554 Acc: 1.00000000
iteration 34400 train loss: 0.24274634 Acc: 1.00000000
iteration 34450 train loss: 0.24618022 Acc: 1.00000000
iteration 34500 train loss: 0.29145792 Acc: 0.87500000
iteration 34550 train loss: 0.28906733 Acc: 0.87500000
iteration 34600 train loss: 0.25226635 Acc: 1.00000000
iteration 34650 train loss: 0.25340137 Acc: 1.00000000
iteration 34700 train loss: 0.24346264 Acc: 1.00000000
iteration 34750 train loss: 0.24154566 Acc: 1.00000000
iteration 34800 train loss: 0.24324356 Acc: 1.00000000
iteration 34850 train loss: 0.24868363 Acc: 1.00000000
iteration 34900 train loss: 0.25547889 Acc: 1.00000000
iteration 34950 train loss: 0.25109255 Acc: 1.00000000
iteration 35000 train loss: 0.24544622 Acc: 1.00000000
epoch train loss: nan Acc: 0.97752923
 40%|████      | 4/10 [21:05<31:35, 315.98s/it]epoch val loss: 0.01214595 Acc: 0.96510273
Epoch 5/10
----------
iteration 35050 train loss: 0.24504884 Acc: 1.00000000
iteration 35100 train loss: 0.25494599 Acc: 0.87500000
iteration 35150 train loss: 0.24104002 Acc: 1.00000000
iteration 35200 train loss: 0.24282056 Acc: 1.00000000
iteration 35250 train loss: 0.24376141 Acc: 1.00000000
iteration 35300 train loss: 0.28828183 Acc: 0.87500000
iteration 35350 train loss: 0.24581720 Acc: 1.00000000
iteration 35400 train loss: 0.24220391 Acc: 1.00000000
iteration 35450 train loss: 0.24104790 Acc: 1.00000000
iteration 35500 train loss: 0.24374367 Acc: 1.00000000
iteration 35550 train loss: 0.24103776 Acc: 1.00000000
iteration 35600 train loss: 0.24287571 Acc: 1.00000000
iteration 35650 train loss: 0.27560812 Acc: 0.87500000
iteration 35700 train loss: 0.24297795 Acc: 1.00000000
iteration 35750 train loss: 0.25734371 Acc: 0.87500000
iteration 35800 train loss: 0.25200057 Acc: 1.00000000
iteration 35850 train loss: 0.24464223 Acc: 1.00000000
iteration 35900 train loss: 0.24940799 Acc: 1.00000000
iteration 35950 train loss: 0.24241769 Acc: 1.00000000
iteration 36000 train loss: 0.28821269 Acc: 0.75000000
iteration 36050 train loss: 0.24246882 Acc: 1.00000000
iteration 36100 train loss: 0.24093279 Acc: 1.00000000
iteration 36150 train loss: 0.24287727 Acc: 1.00000000
iteration 36200 train loss: 0.24406864 Acc: 1.00000000
iteration 36250 train loss: 0.25204346 Acc: 1.00000000
iteration 36300 train loss: 0.24371976 Acc: 1.00000000
iteration 36350 train loss: 0.24302459 Acc: 1.00000000
iteration 36400 train loss: 0.24271093 Acc: 1.00000000
iteration 36450 train loss: 0.24373695 Acc: 1.00000000
iteration 36500 train loss: 0.24862459 Acc: 1.00000000
iteration 36550 train loss: 0.32808775 Acc: 0.87500000
iteration 36600 train loss: 0.24721804 Acc: 1.00000000
iteration 36650 train loss: 0.24138588 Acc: 1.00000000
iteration 36700 train loss: 0.24491836 Acc: 1.00000000
iteration 36750 train loss: 0.24342453 Acc: 1.00000000
iteration 36800 train loss: 0.25658220 Acc: 0.87500000
iteration 36850 train loss: 0.24408835 Acc: 1.00000000
iteration 36900 train loss: 0.24066004 Acc: 1.00000000
iteration 36950 train loss: 0.24479291 Acc: 1.00000000
iteration 37000 train loss: 0.25124356 Acc: 1.00000000
iteration 37050 train loss: 0.25818956 Acc: 0.87500000
iteration 37100 train loss: 0.24302287 Acc: 1.00000000
iteration 37150 train loss: 0.24098924 Acc: 1.00000000
iteration 37200 train loss: 0.24227852 Acc: 1.00000000
iteration 37250 train loss: 0.24556226 Acc: 1.00000000
iteration 37300 train loss: 0.24651226 Acc: 1.00000000
iteration 37350 train loss: 0.24417751 Acc: 1.00000000
iteration 37400 train loss: 0.24300267 Acc: 1.00000000
iteration 37450 train loss: 0.24445343 Acc: 1.00000000
iteration 37500 train loss: 0.24699411 Acc: 1.00000000
iteration 37550 train loss: 0.24577969 Acc: 1.00000000
iteration 37600 train loss: 0.24729931 Acc: 1.00000000
iteration 37650 train loss: 0.26108170 Acc: 0.87500000
iteration 37700 train loss: 0.24352078 Acc: 1.00000000
iteration 37750 train loss: 0.24568596 Acc: 1.00000000
iteration 37800 train loss: 0.24295779 Acc: 1.00000000
iteration 37850 train loss: 0.25088674 Acc: 1.00000000
iteration 37900 train loss: 0.24414527 Acc: 1.00000000
iteration 37950 train loss: 0.27067015 Acc: 0.87500000
iteration 38000 train loss: 0.24568965 Acc: 1.00000000
iteration 38050 train loss: 0.24520925 Acc: 1.00000000
iteration 38100 train loss: 0.24229415 Acc: 1.00000000
iteration 38150 train loss: 0.24181505 Acc: 1.00000000
iteration 38200 train loss: 0.24285981 Acc: 1.00000000
iteration 38250 train loss: 0.24600756 Acc: 1.00000000
iteration 38300 train loss: 0.24240126 Acc: 1.00000000
iteration 38350 train loss: 0.24373211 Acc: 1.00000000
iteration 38400 train loss: 0.24194135 Acc: 1.00000000
iteration 38450 train loss: 0.25965458 Acc: 1.00000000
iteration 38500 train loss: 0.24278115 Acc: 1.00000000
iteration 38550 train loss: 0.24260762 Acc: 1.00000000
iteration 38600 train loss: 0.24344370 Acc: 1.00000000
iteration 38650 train loss: 0.24407049 Acc: 1.00000000
iteration 38700 train loss: 0.24290541 Acc: 1.00000000
iteration 38750 train loss: 0.24267803 Acc: 1.00000000
iteration 38800 train loss: 0.24464977 Acc: 1.00000000
iteration 38850 train loss: 0.24376777 Acc: 1.00000000
iteration 38900 train loss: 0.24380602 Acc: 1.00000000
iteration 38950 train loss: 0.24441233 Acc: 1.00000000
iteration 39000 train loss: 0.24373542 Acc: 1.00000000
iteration 39050 train loss: 0.24537390 Acc: 1.00000000
iteration 39100 train loss: 0.29611686 Acc: 0.87500000
iteration 39150 train loss: 0.24259123 Acc: 1.00000000
iteration 39200 train loss: 0.24695973 Acc: 1.00000000
iteration 39250 train loss: 0.24450770 Acc: 1.00000000
iteration 39300 train loss: 0.25339514 Acc: 0.87500000
iteration 39350 train loss: 0.24212669 Acc: 1.00000000
iteration 39400 train loss: 0.24758147 Acc: 1.00000000
iteration 39450 train loss: 0.24344616 Acc: 1.00000000
iteration 39500 train loss: 0.24340051 Acc: 1.00000000
iteration 39550 train loss: 0.24367751 Acc: 1.00000000
iteration 39600 train loss: 0.24404037 Acc: 1.00000000
iteration 39650 train loss: 0.24718502 Acc: 1.00000000
iteration 39700 train loss: 0.24327552 Acc: 1.00000000
iteration 39750 train loss: 0.24329634 Acc: 1.00000000
iteration 39800 train loss: 0.25475058 Acc: 1.00000000
iteration 39850 train loss: 0.24340092 Acc: 1.00000000
iteration 39900 train loss: 0.24276412 Acc: 1.00000000
iteration 39950 train loss: 0.24342220 Acc: 1.00000000
iteration 40000 train loss: 0.24602348 Acc: 1.00000000
iteration 40050 train loss: 0.24403574 Acc: 1.00000000
iteration 40100 train loss: 0.24332502 Acc: 1.00000000
iteration 40150 train loss: 0.24424991 Acc: 1.00000000
iteration 40200 train loss: 0.28833717 Acc: 0.87500000
iteration 40250 train loss: 0.24420096 Acc: 1.00000000
iteration 40300 train loss: 0.24450365 Acc: 1.00000000
iteration 40350 train loss: 0.24279739 Acc: 1.00000000
iteration 40400 train loss: 0.24265362 Acc: 1.00000000
iteration 40450 train loss: 0.24480166 Acc: 1.00000000
iteration 40500 train loss: 0.25855720 Acc: 0.87500000
iteration 40550 train loss: 0.26420319 Acc: 1.00000000
iteration 40600 train loss: 0.24322556 Acc: 1.00000000
iteration 40650 train loss: 0.24423099 Acc: 1.00000000
iteration 40700 train loss: 0.24356416 Acc: 1.00000000
iteration 40750 train loss: 0.24466352 Acc: 1.00000000
iteration 40800 train loss: 0.24383618 Acc: 1.00000000
iteration 40850 train loss: 0.24336754 Acc: 1.00000000
iteration 40900 train loss: 0.37733996 Acc: 0.87500000
iteration 40950 train loss: 0.25665385 Acc: 0.87500000
iteration 41000 train loss: 0.24290107 Acc: 1.00000000
iteration 41050 train loss: 0.25709879 Acc: 1.00000000
iteration 41100 train loss: 0.24479692 Acc: 1.00000000
iteration 41150 train loss: 0.27601403 Acc: 0.75000000
iteration 41200 train loss: 0.24384573 Acc: 1.00000000
iteration 41250 train loss: 0.24828804 Acc: 1.00000000
iteration 41300 train loss: 0.24455304 Acc: 1.00000000
iteration 41350 train loss: 0.24345954 Acc: 1.00000000
iteration 41400 train loss: 0.24759987 Acc: 1.00000000
iteration 41450 train loss: 0.24495181 Acc: 1.00000000
iteration 41500 train loss: 0.25009459 Acc: 1.00000000
iteration 41550 train loss: 0.24159577 Acc: 1.00000000
iteration 41600 train loss: 0.24283953 Acc: 1.00000000
iteration 41650 train loss: 0.24751477 Acc: 1.00000000
iteration 41700 train loss: 0.24703471 Acc: 1.00000000
iteration 41750 train loss: 0.24590510 Acc: 1.00000000
iteration 41800 train loss: 0.24604024 Acc: 1.00000000
iteration 41850 train loss: 0.24345204 Acc: 1.00000000
iteration 41900 train loss: 0.24462929 Acc: 1.00000000
iteration 41950 train loss: 0.24295646 Acc: 1.00000000
iteration 42000 train loss: 0.24373053 Acc: 1.00000000
iteration 42050 train loss: 0.24377459 Acc: 1.00000000
iteration 42100 train loss: 0.24462824 Acc: 1.00000000
iteration 42150 train loss: 0.24329749 Acc: 1.00000000
iteration 42200 train loss: 0.24312662 Acc: 1.00000000
iteration 42250 train loss: 0.24537744 Acc: 1.00000000
iteration 42300 train loss: 0.25332364 Acc: 1.00000000
iteration 42350 train loss: 0.24444474 Acc: 1.00000000
iteration 42400 train loss: 0.24377419 Acc: 1.00000000
iteration 42450 train loss: 0.24345303 Acc: 1.00000000
iteration 42500 train loss: 0.24362604 Acc: 1.00000000
iteration 42550 train loss: 0.24189481 Acc: 1.00000000
iteration 42600 train loss: 0.24909359 Acc: 1.00000000
iteration 42650 train loss: 0.24482758 Acc: 1.00000000
iteration 42700 train loss: 0.24400744 Acc: 1.00000000
iteration 42750 train loss: 0.25238645 Acc: 1.00000000
iteration 42800 train loss: 0.24326095 Acc: 1.00000000
iteration 42850 train loss: 0.24288285 Acc: 1.00000000
iteration 42900 train loss: 0.24921843 Acc: 1.00000000
iteration 42950 train loss: 0.25158200 Acc: 1.00000000
iteration 43000 train loss: 0.24457337 Acc: 1.00000000
iteration 43050 train loss: 0.24922729 Acc: 1.00000000
iteration 43100 train loss: 0.24367209 Acc: 1.00000000
iteration 43150 train loss: 0.24874640 Acc: 1.00000000
iteration 43200 train loss: 0.24427028 Acc: 1.00000000
iteration 43250 train loss: 0.24494058 Acc: 1.00000000
iteration 43300 train loss: 0.24792552 Acc: 1.00000000
iteration 43350 train loss: 0.24289989 Acc: 1.00000000
iteration 43400 train loss: 0.24224143 Acc: 1.00000000
iteration 43450 train loss: 0.24211487 Acc: 1.00000000
iteration 43500 train loss: 0.24300702 Acc: 1.00000000
iteration 43550 train loss: 0.24552090 Acc: 1.00000000
iteration 43600 train loss: 0.24387489 Acc: 1.00000000
iteration 43650 train loss: 0.25135151 Acc: 1.00000000
iteration 43700 train loss: 0.24508557 Acc: 1.00000000
iteration 43750 train loss: 0.24537283 Acc: 1.00000000
epoch train loss: 0.24920074 Acc: 0.98074341
 50%|█████     | 5/10 [26:19<26:16, 315.21s/it]epoch val loss: 0.01208195 Acc: 0.96596497
Epoch 6/10
----------
iteration 43800 train loss: 0.24385759 Acc: 1.00000000
iteration 43850 train loss: 0.24227576 Acc: 1.00000000
iteration 43900 train loss: 0.24886419 Acc: 1.00000000
iteration 43950 train loss: 0.24406947 Acc: 1.00000000
iteration 44000 train loss: 0.24599786 Acc: 1.00000000
iteration 44050 train loss: 0.24378780 Acc: 1.00000000
iteration 44100 train loss: 0.24519581 Acc: 1.00000000
iteration 44150 train loss: 0.24335872 Acc: 1.00000000
iteration 44200 train loss: 0.24853677 Acc: 1.00000000
iteration 44250 train loss: 0.24261442 Acc: 1.00000000
iteration 44300 train loss: 0.24210234 Acc: 1.00000000
iteration 44350 train loss: 0.24317329 Acc: 1.00000000
iteration 44400 train loss: 0.24370138 Acc: 1.00000000
iteration 44450 train loss: 0.24582872 Acc: 1.00000000
iteration 44500 train loss: 0.24264398 Acc: 1.00000000
iteration 44550 train loss: 0.24187312 Acc: 1.00000000
iteration 44600 train loss: 0.24787258 Acc: 1.00000000
iteration 44650 train loss: 0.24270293 Acc: 1.00000000
iteration 44700 train loss: 0.24411248 Acc: 1.00000000
iteration 44750 train loss: 0.24269588 Acc: 1.00000000
iteration 44800 train loss: 0.24211922 Acc: 1.00000000
iteration 44850 train loss: 0.26179066 Acc: 0.87500000
iteration 44900 train loss: 0.24389341 Acc: 1.00000000
iteration 44950 train loss: 0.24171276 Acc: 1.00000000
iteration 45000 train loss: 0.24398963 Acc: 1.00000000
iteration 45050 train loss: 0.24236327 Acc: 1.00000000
iteration 45100 train loss: 0.24270618 Acc: 1.00000000
iteration 45150 train loss: 0.24232468 Acc: 1.00000000
iteration 45200 train loss: 0.24409741 Acc: 1.00000000
iteration 45250 train loss: 0.24257590 Acc: 1.00000000
iteration 45300 train loss: 0.26330346 Acc: 0.87500000
iteration 45350 train loss: 0.24271353 Acc: 1.00000000
iteration 45400 train loss: 0.25668544 Acc: 0.87500000
iteration 45450 train loss: 0.24096815 Acc: 1.00000000
iteration 45500 train loss: 0.24233817 Acc: 1.00000000
iteration 45550 train loss: 0.25341645 Acc: 1.00000000
iteration 45600 train loss: 0.24318984 Acc: 1.00000000
iteration 45650 train loss: 0.24283139 Acc: 1.00000000
iteration 45700 train loss: 0.24301814 Acc: 1.00000000
iteration 45750 train loss: 0.24908517 Acc: 1.00000000
iteration 45800 train loss: 0.25008485 Acc: 1.00000000
iteration 45850 train loss: 0.24358711 Acc: 1.00000000
iteration 45900 train loss: 0.24122699 Acc: 1.00000000
iteration 45950 train loss: 0.24236277 Acc: 1.00000000
iteration 46000 train loss: 0.24292415 Acc: 1.00000000
iteration 46050 train loss: 0.24390565 Acc: 1.00000000
iteration 46100 train loss: 0.24401516 Acc: 1.00000000
iteration 46150 train loss: 0.24335077 Acc: 1.00000000
iteration 46200 train loss: 0.24563618 Acc: 1.00000000
iteration 46250 train loss: 0.24402484 Acc: 1.00000000
iteration 46300 train loss: 0.25638735 Acc: 0.87500000
iteration 46350 train loss: 0.24121080 Acc: 1.00000000
iteration 46400 train loss: 0.24127336 Acc: 1.00000000
iteration 46450 train loss: 0.24340999 Acc: 1.00000000
iteration 46500 train loss: 0.26607704 Acc: 0.87500000
iteration 46550 train loss: 0.24080707 Acc: 1.00000000
iteration 46600 train loss: 0.24377860 Acc: 1.00000000
iteration 46650 train loss: 0.24700136 Acc: 1.00000000
iteration 46700 train loss: 0.24429157 Acc: 1.00000000
iteration 46750 train loss: 0.25326559 Acc: 1.00000000
iteration 46800 train loss: 0.24168132 Acc: 1.00000000
iteration 46850 train loss: 0.24247158 Acc: 1.00000000
iteration 46900 train loss: 0.25043663 Acc: 1.00000000
iteration 46950 train loss: 0.26279396 Acc: 0.87500000
iteration 47000 train loss: 0.24226908 Acc: 1.00000000
iteration 47050 train loss: 0.24361295 Acc: 1.00000000
iteration 47100 train loss: 0.24431871 Acc: 1.00000000
iteration 47150 train loss: 0.25839832 Acc: 0.87500000
iteration 47200 train loss: 0.24386603 Acc: 1.00000000
iteration 47250 train loss: 0.24421418 Acc: 1.00000000
iteration 47300 train loss: 0.24418148 Acc: 1.00000000
iteration 47350 train loss: 0.24261743 Acc: 1.00000000
iteration 47400 train loss: 0.24290358 Acc: 1.00000000
iteration 47450 train loss: 0.24343275 Acc: 1.00000000
iteration 47500 train loss: 0.24333735 Acc: 1.00000000
iteration 47550 train loss: 0.24247377 Acc: 1.00000000
iteration 47600 train loss: 0.24362531 Acc: 1.00000000
iteration 47650 train loss: 0.24391554 Acc: 1.00000000
iteration 47700 train loss: 0.24906541 Acc: 1.00000000
iteration 47750 train loss: 0.26227766 Acc: 0.87500000
iteration 47800 train loss: 0.24328835 Acc: 1.00000000
iteration 47850 train loss: 0.26865941 Acc: 0.87500000
iteration 47900 train loss: 0.24305077 Acc: 1.00000000
iteration 47950 train loss: 0.24462134 Acc: 1.00000000
iteration 48000 train loss: 0.24194126 Acc: 1.00000000
iteration 48050 train loss: 0.24372038 Acc: 1.00000000
iteration 48100 train loss: 0.24562173 Acc: 1.00000000
iteration 48150 train loss: 0.24234834 Acc: 1.00000000
iteration 48200 train loss: 0.24414322 Acc: 1.00000000
iteration 48250 train loss: 0.24529850 Acc: 1.00000000
iteration 48300 train loss: 0.24312413 Acc: 1.00000000
iteration 48350 train loss: 0.24321777 Acc: 1.00000000
iteration 48400 train loss: 0.24369806 Acc: 1.00000000
iteration 48450 train loss: 0.25807062 Acc: 0.87500000
iteration 48500 train loss: 0.24271524 Acc: 1.00000000
iteration 48550 train loss: 0.24319978 Acc: 1.00000000
iteration 48600 train loss: 0.25071305 Acc: 1.00000000
iteration 48650 train loss: 0.25303623 Acc: 1.00000000
iteration 48700 train loss: 0.24261458 Acc: 1.00000000
iteration 48750 train loss: 0.24351270 Acc: 1.00000000
iteration 48800 train loss: 0.24436338 Acc: 1.00000000
iteration 48850 train loss: 0.24371070 Acc: 1.00000000
iteration 48900 train loss: 0.24254331 Acc: 1.00000000
iteration 48950 train loss: 0.24307635 Acc: 1.00000000
iteration 49000 train loss: 0.25386491 Acc: 1.00000000
iteration 49050 train loss: 0.24256153 Acc: 1.00000000
iteration 49100 train loss: 0.24455263 Acc: 1.00000000
iteration 49150 train loss: 0.25184166 Acc: 1.00000000
iteration 49200 train loss: 0.24253513 Acc: 1.00000000
iteration 49250 train loss: 0.24399237 Acc: 1.00000000
iteration 49300 train loss: 0.24359801 Acc: 1.00000000
iteration 49350 train loss: 0.24365778 Acc: 1.00000000
iteration 49400 train loss: 0.24433470 Acc: 1.00000000
iteration 49450 train loss: 0.24318811 Acc: 1.00000000
iteration 49500 train loss: 0.24404909 Acc: 1.00000000
iteration 49550 train loss: 0.24260019 Acc: 1.00000000
iteration 49600 train loss: 0.24452034 Acc: 1.00000000
iteration 49650 train loss: 0.24416180 Acc: 1.00000000
iteration 49700 train loss: 0.24298438 Acc: 1.00000000
iteration 49750 train loss: 0.24186362 Acc: 1.00000000
iteration 49800 train loss: 0.24059394 Acc: 1.00000000
iteration 49850 train loss: 0.24236013 Acc: 1.00000000
iteration 49900 train loss: 0.24401487 Acc: 1.00000000
iteration 49950 train loss: 0.24595912 Acc: 1.00000000
iteration 50000 train loss: 0.24510589 Acc: 1.00000000
iteration 50050 train loss: 0.24239479 Acc: 1.00000000
iteration 50100 train loss: 0.24259724 Acc: 1.00000000
iteration 50150 train loss: 0.24451375 Acc: 1.00000000
iteration 50200 train loss: 0.24366774 Acc: 1.00000000
iteration 50250 train loss: 0.24286057 Acc: 1.00000000
iteration 50300 train loss: 0.24178150 Acc: 1.00000000
iteration 50350 train loss: 0.24392304 Acc: 1.00000000
iteration 50400 train loss: 0.24149230 Acc: 1.00000000
iteration 50450 train loss: 0.24422431 Acc: 1.00000000
iteration 50500 train loss: 0.24907221 Acc: 1.00000000
iteration 50550 train loss: 0.24862510 Acc: 1.00000000
iteration 50600 train loss: 0.24687213 Acc: 1.00000000
iteration 50650 train loss: 0.24402680 Acc: 1.00000000
iteration 50700 train loss: 0.24349707 Acc: 1.00000000
iteration 50750 train loss: 0.26577437 Acc: 0.87500000
iteration 50800 train loss: 0.24284621 Acc: 1.00000000
iteration 50850 train loss: 0.24303839 Acc: 1.00000000
iteration 50900 train loss: 0.24318847 Acc: 1.00000000
iteration 50950 train loss: 0.24520606 Acc: 1.00000000
iteration 51000 train loss: 0.24228443 Acc: 1.00000000
iteration 51050 train loss: 0.24907291 Acc: 1.00000000
iteration 51100 train loss: 0.24013190 Acc: 1.00000000
iteration 51150 train loss: 0.24386744 Acc: 1.00000000
iteration 51200 train loss: 0.24290217 Acc: 1.00000000
iteration 51250 train loss: 0.24759619 Acc: 1.00000000
iteration 51300 train loss: 0.24285160 Acc: 1.00000000
iteration 51350 train loss: 0.24256490 Acc: 1.00000000
iteration 51400 train loss: 0.24348058 Acc: 1.00000000
iteration 51450 train loss: 0.24370669 Acc: 1.00000000
iteration 51500 train loss: 0.24369489 Acc: 1.00000000
iteration 51550 train loss: 0.24183466 Acc: 1.00000000
iteration 51600 train loss: 0.24091956 Acc: 1.00000000
iteration 51650 train loss: 0.26181614 Acc: 0.87500000
iteration 51700 train loss: 0.25267765 Acc: 1.00000000
iteration 51750 train loss: 0.24704859 Acc: 1.00000000
iteration 51800 train loss: 0.24238050 Acc: 1.00000000
iteration 51850 train loss: 0.24465181 Acc: 1.00000000
iteration 51900 train loss: 0.24185045 Acc: 1.00000000
iteration 51950 train loss: 0.24617195 Acc: 1.00000000
iteration 52000 train loss: 0.24160548 Acc: 1.00000000
iteration 52050 train loss: 0.24372979 Acc: 1.00000000
iteration 52100 train loss: 0.24042332 Acc: 1.00000000
iteration 52150 train loss: 0.24227674 Acc: 1.00000000
iteration 52200 train loss: 0.24240172 Acc: 1.00000000
iteration 52250 train loss: 0.24395138 Acc: 1.00000000
iteration 52300 train loss: 0.24395238 Acc: 1.00000000
iteration 52350 train loss: 0.24354178 Acc: 1.00000000
iteration 52400 train loss: 0.24574198 Acc: 1.00000000
iteration 52450 train loss: 0.24373181 Acc: 1.00000000
iteration 52500 train loss: 0.24116306 Acc: 1.00000000
epoch train loss: nan Acc: 0.98878604
 60%|██████    | 6/10 [31:33<20:59, 314.92s/it]epoch val loss: 0.01120684 Acc: 0.96921128
Epoch 7/10
----------
iteration 52550 train loss: 0.24223621 Acc: 1.00000000
iteration 52600 train loss: 0.24312520 Acc: 1.00000000
iteration 52650 train loss: 0.24246086 Acc: 1.00000000
iteration 52700 train loss: 0.24277054 Acc: 1.00000000
iteration 52750 train loss: 0.24343911 Acc: 1.00000000
iteration 52800 train loss: 0.24387142 Acc: 1.00000000
iteration 52850 train loss: 0.24521944 Acc: 1.00000000
iteration 52900 train loss: 0.24780147 Acc: 1.00000000
iteration 52950 train loss: 0.26348808 Acc: 0.87500000
iteration 53000 train loss: 0.24318096 Acc: 1.00000000
iteration 53050 train loss: 0.24320363 Acc: 1.00000000
iteration 53100 train loss: 0.24217241 Acc: 1.00000000
iteration 53150 train loss: 0.24302432 Acc: 1.00000000
iteration 53200 train loss: 0.24238031 Acc: 1.00000000
iteration 53250 train loss: 0.26747525 Acc: 0.87500000
iteration 53300 train loss: 0.24327485 Acc: 1.00000000
iteration 53350 train loss: 0.24138442 Acc: 1.00000000
iteration 53400 train loss: 0.24919041 Acc: 1.00000000
iteration 53450 train loss: 0.24578200 Acc: 1.00000000
iteration 53500 train loss: 0.24189109 Acc: 1.00000000
iteration 53550 train loss: 0.24341407 Acc: 1.00000000
iteration 53600 train loss: 0.24461123 Acc: 1.00000000
iteration 53650 train loss: 0.24231690 Acc: 1.00000000
iteration 53700 train loss: 0.24092160 Acc: 1.00000000
iteration 53750 train loss: 0.24608694 Acc: 1.00000000
iteration 53800 train loss: 0.24200545 Acc: 1.00000000
iteration 53850 train loss: 0.24348335 Acc: 1.00000000
iteration 53900 train loss: 0.24463616 Acc: 1.00000000
iteration 53950 train loss: 0.24139325 Acc: 1.00000000
iteration 54000 train loss: 0.24376816 Acc: 1.00000000
iteration 54050 train loss: 0.24267623 Acc: 1.00000000
iteration 54100 train loss: 0.24756667 Acc: 1.00000000
iteration 54150 train loss: 0.24246800 Acc: 1.00000000
iteration 54200 train loss: 0.24445163 Acc: 1.00000000
iteration 54250 train loss: 0.24504212 Acc: 1.00000000
iteration 54300 train loss: 0.24339852 Acc: 1.00000000
iteration 54350 train loss: 0.24399804 Acc: 1.00000000
iteration 54400 train loss: 0.24307638 Acc: 1.00000000
iteration 54450 train loss: 0.24692717 Acc: 1.00000000
iteration 54500 train loss: 0.24371709 Acc: 1.00000000
iteration 54550 train loss: 0.24494940 Acc: 1.00000000
iteration 54600 train loss: 0.24463664 Acc: 1.00000000
iteration 54650 train loss: 0.25871423 Acc: 0.87500000
iteration 54700 train loss: 0.24575464 Acc: 1.00000000
iteration 54750 train loss: 0.24458894 Acc: 1.00000000
iteration 54800 train loss: 0.24365430 Acc: 1.00000000
iteration 54850 train loss: 0.24267347 Acc: 1.00000000
iteration 54900 train loss: 0.24308856 Acc: 1.00000000
iteration 54950 train loss: 0.24225701 Acc: 1.00000000
iteration 55000 train loss: 0.25465143 Acc: 0.87500000
iteration 55050 train loss: 0.24357107 Acc: 1.00000000
iteration 55100 train loss: 0.24518095 Acc: 1.00000000
iteration 55150 train loss: 0.24572371 Acc: 1.00000000
iteration 55200 train loss: 0.24369481 Acc: 1.00000000
iteration 55250 train loss: 0.24521780 Acc: 1.00000000
iteration 55300 train loss: 0.24184768 Acc: 1.00000000
iteration 55350 train loss: 0.24771369 Acc: 1.00000000
iteration 55400 train loss: 0.24152902 Acc: 1.00000000
iteration 55450 train loss: 0.25294352 Acc: 1.00000000
iteration 55500 train loss: 0.24065638 Acc: 1.00000000
iteration 55550 train loss: 0.24353510 Acc: 1.00000000
iteration 55600 train loss: 0.24325056 Acc: 1.00000000
iteration 55650 train loss: 0.24370229 Acc: 1.00000000
iteration 55700 train loss: 0.24226770 Acc: 1.00000000
iteration 55750 train loss: 0.24675433 Acc: 1.00000000
iteration 55800 train loss: 0.24331747 Acc: 1.00000000
iteration 55850 train loss: 0.24299544 Acc: 1.00000000
iteration 55900 train loss: 0.24184881 Acc: 1.00000000
iteration 55950 train loss: 0.26112559 Acc: 0.87500000
iteration 56000 train loss: 0.25292888 Acc: 1.00000000
iteration 56050 train loss: 0.25146091 Acc: 1.00000000
iteration 56100 train loss: 0.24182428 Acc: 1.00000000
iteration 56150 train loss: 0.24271134 Acc: 1.00000000
iteration 56200 train loss: 0.24405803 Acc: 1.00000000
iteration 56250 train loss: 0.24374884 Acc: 1.00000000
iteration 56300 train loss: 0.24325362 Acc: 1.00000000
iteration 56350 train loss: 0.24376339 Acc: 1.00000000
iteration 56400 train loss: 0.24379180 Acc: 1.00000000
iteration 56450 train loss: 0.24193488 Acc: 1.00000000
iteration 56500 train loss: 0.24842903 Acc: 1.00000000
iteration 56550 train loss: 0.24335189 Acc: 1.00000000
iteration 56600 train loss: 0.24839506 Acc: 1.00000000
iteration 56650 train loss: 0.24365467 Acc: 1.00000000
iteration 56700 train loss: 0.24265286 Acc: 1.00000000
iteration 56750 train loss: 0.24347967 Acc: 1.00000000
iteration 56800 train loss: 0.24330951 Acc: 1.00000000
iteration 56850 train loss: 0.24844772 Acc: 1.00000000
iteration 56900 train loss: 0.24325684 Acc: 1.00000000
iteration 56950 train loss: 0.24391188 Acc: 1.00000000
iteration 57000 train loss: 0.24173003 Acc: 1.00000000
iteration 57050 train loss: 0.24369510 Acc: 1.00000000
iteration 57100 train loss: 0.24325436 Acc: 1.00000000
iteration 57150 train loss: 0.24663056 Acc: 1.00000000
iteration 57200 train loss: 0.24179856 Acc: 1.00000000
iteration 57250 train loss: 0.24331881 Acc: 1.00000000
iteration 57300 train loss: 0.24444346 Acc: 1.00000000
iteration 57350 train loss: 0.24465623 Acc: 1.00000000
iteration 57400 train loss: 0.24262850 Acc: 1.00000000
iteration 57450 train loss: 0.24323770 Acc: 1.00000000
iteration 57500 train loss: 0.24429637 Acc: 1.00000000
iteration 57550 train loss: 0.24113256 Acc: 1.00000000
iteration 57600 train loss: 0.24360658 Acc: 1.00000000
iteration 57650 train loss: 0.24123415 Acc: 1.00000000
iteration 57700 train loss: 0.24280646 Acc: 1.00000000
iteration 57750 train loss: 0.24292077 Acc: 1.00000000
iteration 57800 train loss: 0.24234164 Acc: 1.00000000
iteration 57850 train loss: 0.24222215 Acc: 1.00000000
iteration 57900 train loss: 0.24375640 Acc: 1.00000000
iteration 57950 train loss: 0.24492721 Acc: 1.00000000
iteration 58000 train loss: 0.24302579 Acc: 1.00000000
iteration 58050 train loss: 0.24363866 Acc: 1.00000000
iteration 58100 train loss: 0.24072674 Acc: 1.00000000
iteration 58150 train loss: 0.24117659 Acc: 1.00000000
iteration 58200 train loss: 0.24416149 Acc: 1.00000000
iteration 58250 train loss: 0.24729855 Acc: 1.00000000
iteration 58300 train loss: 0.24256513 Acc: 1.00000000
iteration 58350 train loss: 0.24305812 Acc: 1.00000000
iteration 58400 train loss: 0.24343276 Acc: 1.00000000
iteration 58450 train loss: 0.25637865 Acc: 0.87500000
iteration 58500 train loss: 0.24562788 Acc: 1.00000000
iteration 58550 train loss: 0.24381983 Acc: 1.00000000
iteration 58600 train loss: 0.24343279 Acc: 1.00000000
iteration 58650 train loss: 0.26260114 Acc: 0.87500000
iteration 58700 train loss: 0.24292633 Acc: 1.00000000
iteration 58750 train loss: 0.24548167 Acc: 1.00000000
iteration 58800 train loss: 0.24186882 Acc: 1.00000000
iteration 58850 train loss: 0.24540310 Acc: 1.00000000
iteration 58900 train loss: 0.24253681 Acc: 1.00000000
iteration 58950 train loss: 0.24675617 Acc: 1.00000000
iteration 59000 train loss: 0.24431315 Acc: 1.00000000
iteration 59050 train loss: 0.24415088 Acc: 1.00000000
iteration 59100 train loss: 0.24314781 Acc: 1.00000000
iteration 59150 train loss: 0.24344486 Acc: 1.00000000
iteration 59200 train loss: 0.24310109 Acc: 1.00000000
iteration 59250 train loss: 0.24201347 Acc: 1.00000000
iteration 59300 train loss: 0.24439228 Acc: 1.00000000
iteration 59350 train loss: 0.24125013 Acc: 1.00000000
iteration 59400 train loss: 0.24477179 Acc: 1.00000000
iteration 59450 train loss: 0.24605586 Acc: 1.00000000
iteration 59500 train loss: 0.24201418 Acc: 1.00000000
iteration 59550 train loss: 0.24419051 Acc: 1.00000000
iteration 59600 train loss: 0.24322204 Acc: 1.00000000
iteration 59650 train loss: 0.24300721 Acc: 1.00000000
iteration 59700 train loss: 0.24071245 Acc: 1.00000000
iteration 59750 train loss: 0.24298397 Acc: 1.00000000
iteration 59800 train loss: 0.24230897 Acc: 1.00000000
iteration 59850 train loss: 0.24167791 Acc: 1.00000000
iteration 59900 train loss: 0.24221621 Acc: 1.00000000
iteration 59950 train loss: 0.24523847 Acc: 1.00000000
iteration 60000 train loss: 0.24112663 Acc: 1.00000000
iteration 60050 train loss: 0.24245386 Acc: 1.00000000
iteration 60100 train loss: 0.24432063 Acc: 1.00000000
iteration 60150 train loss: 0.24287656 Acc: 1.00000000
iteration 60200 train loss: 0.24344106 Acc: 1.00000000
iteration 60250 train loss: 0.24220872 Acc: 1.00000000
iteration 60300 train loss: 0.25176987 Acc: 1.00000000
iteration 60350 train loss: 0.26028782 Acc: 0.87500000
iteration 60400 train loss: 0.24204525 Acc: 1.00000000
iteration 60450 train loss: 0.24448688 Acc: 1.00000000
iteration 60500 train loss: 0.26033908 Acc: 0.87500000
iteration 60550 train loss: 0.24291757 Acc: 1.00000000
iteration 60600 train loss: 0.24300596 Acc: 1.00000000
iteration 60650 train loss: 0.24434596 Acc: 1.00000000
iteration 60700 train loss: 0.24147218 Acc: 1.00000000
iteration 60750 train loss: 0.24295501 Acc: 1.00000000
iteration 60800 train loss: 0.24295586 Acc: 1.00000000
iteration 60850 train loss: 0.24384855 Acc: 1.00000000
iteration 60900 train loss: 0.24736805 Acc: 1.00000000
iteration 60950 train loss: 0.24254541 Acc: 1.00000000
iteration 61000 train loss: 0.24330276 Acc: 1.00000000
iteration 61050 train loss: 0.24135713 Acc: 1.00000000
iteration 61100 train loss: 0.24342725 Acc: 1.00000000
iteration 61150 train loss: 0.24371366 Acc: 1.00000000
iteration 61200 train loss: 0.24301100 Acc: 1.00000000
iteration 61250 train loss: 0.26695842 Acc: 0.87500000
epoch train loss: nan Acc: 0.99155736
 70%|███████   | 7/10 [36:47<15:44, 314.72s/it]epoch val loss: 0.01197910 Acc: 0.96895766
Epoch 8/10
----------
iteration 61300 train loss: 0.24306707 Acc: 1.00000000
iteration 61350 train loss: 0.24341059 Acc: 1.00000000
iteration 61400 train loss: 0.24321617 Acc: 1.00000000
iteration 61450 train loss: 0.24302566 Acc: 1.00000000
iteration 61500 train loss: 0.24324220 Acc: 1.00000000
iteration 61550 train loss: 0.24297014 Acc: 1.00000000
iteration 61600 train loss: 0.24386062 Acc: 1.00000000
iteration 61650 train loss: 0.24248864 Acc: 1.00000000
iteration 61700 train loss: 0.24165338 Acc: 1.00000000
iteration 61750 train loss: 0.24818341 Acc: 1.00000000
iteration 61800 train loss: 0.24376622 Acc: 1.00000000
iteration 61850 train loss: 0.24165803 Acc: 1.00000000
iteration 61900 train loss: 0.24492154 Acc: 1.00000000
iteration 61950 train loss: 0.24307239 Acc: 1.00000000
iteration 62000 train loss: 0.24469455 Acc: 1.00000000
iteration 62050 train loss: 0.24222724 Acc: 1.00000000
iteration 62100 train loss: 0.24190964 Acc: 1.00000000
iteration 62150 train loss: 0.24302612 Acc: 1.00000000
iteration 62200 train loss: 0.24252777 Acc: 1.00000000
iteration 62250 train loss: 0.24157652 Acc: 1.00000000
iteration 62300 train loss: 0.24109805 Acc: 1.00000000
iteration 62350 train loss: 0.24203677 Acc: 1.00000000
iteration 62400 train loss: 0.24148594 Acc: 1.00000000
iteration 62450 train loss: 0.24450466 Acc: 1.00000000
iteration 62500 train loss: 0.24277024 Acc: 1.00000000
iteration 62550 train loss: 0.24308525 Acc: 1.00000000
iteration 62600 train loss: 0.24870737 Acc: 1.00000000
iteration 62650 train loss: 0.24386026 Acc: 1.00000000
iteration 62700 train loss: 0.24267571 Acc: 1.00000000
iteration 62750 train loss: 0.24330769 Acc: 1.00000000
iteration 62800 train loss: 0.24375625 Acc: 1.00000000
iteration 62850 train loss: 0.24285789 Acc: 1.00000000
iteration 62900 train loss: 0.24365954 Acc: 1.00000000
iteration 62950 train loss: 0.24370469 Acc: 1.00000000
iteration 63000 train loss: 0.24292864 Acc: 1.00000000
iteration 63050 train loss: 0.24169895 Acc: 1.00000000
iteration 63100 train loss: 0.24376009 Acc: 1.00000000
iteration 63150 train loss: 0.24327919 Acc: 1.00000000
iteration 63200 train loss: 0.24460921 Acc: 1.00000000
iteration 63250 train loss: 0.24450365 Acc: 1.00000000
iteration 63300 train loss: 0.24286933 Acc: 1.00000000
iteration 63350 train loss: 0.24170962 Acc: 1.00000000
iteration 63400 train loss: 0.24362814 Acc: 1.00000000
iteration 63450 train loss: 0.24278001 Acc: 1.00000000
iteration 63500 train loss: 0.25224891 Acc: 1.00000000
iteration 63550 train loss: 0.24781896 Acc: 1.00000000
iteration 63600 train loss: 0.24436301 Acc: 1.00000000
iteration 63650 train loss: 0.24089782 Acc: 1.00000000
iteration 63700 train loss: 0.24491768 Acc: 1.00000000
iteration 63750 train loss: 0.25138775 Acc: 1.00000000
iteration 63800 train loss: 0.24257368 Acc: 1.00000000
iteration 63850 train loss: 0.24330799 Acc: 1.00000000
iteration 63900 train loss: 0.24345174 Acc: 1.00000000
iteration 63950 train loss: 0.24246845 Acc: 1.00000000
iteration 64000 train loss: 0.24303435 Acc: 1.00000000
iteration 64050 train loss: 0.24138682 Acc: 1.00000000
iteration 64100 train loss: 0.24181548 Acc: 1.00000000
iteration 64150 train loss: 0.24418160 Acc: 1.00000000
iteration 64200 train loss: 0.24521658 Acc: 1.00000000
iteration 64250 train loss: 0.24414803 Acc: 1.00000000
iteration 64300 train loss: 0.24302295 Acc: 1.00000000
iteration 64350 train loss: 0.24474312 Acc: 1.00000000
iteration 64400 train loss: 0.26547140 Acc: 0.87500000
iteration 64450 train loss: 0.24239375 Acc: 1.00000000
iteration 64500 train loss: 0.24220710 Acc: 1.00000000
iteration 64550 train loss: 0.24330999 Acc: 1.00000000
iteration 64600 train loss: 0.24327545 Acc: 1.00000000
iteration 64650 train loss: 0.25446141 Acc: 1.00000000
iteration 64700 train loss: 0.24329324 Acc: 1.00000000
iteration 64750 train loss: 0.24121325 Acc: 1.00000000
iteration 64800 train loss: 0.24416633 Acc: 1.00000000
iteration 64850 train loss: 0.24312705 Acc: 1.00000000
iteration 64900 train loss: 0.24327520 Acc: 1.00000000
iteration 64950 train loss: 0.24687572 Acc: 1.00000000
iteration 65000 train loss: 0.24314551 Acc: 1.00000000
iteration 65050 train loss: 0.24387783 Acc: 1.00000000
iteration 65100 train loss: 0.24177286 Acc: 1.00000000
iteration 65150 train loss: 0.24239247 Acc: 1.00000000
iteration 65200 train loss: 0.24482964 Acc: 1.00000000
iteration 65250 train loss: 0.24485806 Acc: 1.00000000
iteration 65300 train loss: 0.24458866 Acc: 1.00000000
iteration 65350 train loss: 0.24399261 Acc: 1.00000000
iteration 65400 train loss: 0.24298595 Acc: 1.00000000
iteration 65450 train loss: 0.24278720 Acc: 1.00000000
iteration 65500 train loss: 0.24338266 Acc: 1.00000000
iteration 65550 train loss: 0.24388026 Acc: 1.00000000
iteration 65600 train loss: 0.24246114 Acc: 1.00000000
iteration 65650 train loss: 0.24301639 Acc: 1.00000000
iteration 65700 train loss: 0.24257365 Acc: 1.00000000
iteration 65750 train loss: 0.24178313 Acc: 1.00000000
iteration 65800 train loss: 0.24213490 Acc: 1.00000000
iteration 65850 train loss: 0.24360391 Acc: 1.00000000
iteration 65900 train loss: 0.24353422 Acc: 1.00000000
iteration 65950 train loss: 0.24491172 Acc: 1.00000000
iteration 66000 train loss: 0.24624886 Acc: 1.00000000
iteration 66050 train loss: 0.24295512 Acc: 1.00000000
iteration 66100 train loss: 0.24413717 Acc: 1.00000000
iteration 66150 train loss: 0.24841815 Acc: 1.00000000
iteration 66200 train loss: 0.25958711 Acc: 1.00000000
iteration 66250 train loss: 0.24276702 Acc: 1.00000000
iteration 66300 train loss: 0.24828456 Acc: 1.00000000
iteration 66350 train loss: 0.24395029 Acc: 1.00000000
iteration 66400 train loss: 0.24412015 Acc: 1.00000000
iteration 66450 train loss: 0.24363124 Acc: 1.00000000
iteration 66500 train loss: 0.24353205 Acc: 1.00000000
iteration 66550 train loss: 0.24361940 Acc: 1.00000000
iteration 66600 train loss: 0.24293831 Acc: 1.00000000
iteration 66650 train loss: 0.26191300 Acc: 0.87500000
iteration 66700 train loss: 0.24360549 Acc: 1.00000000
iteration 66750 train loss: 0.24134313 Acc: 1.00000000
iteration 66800 train loss: 0.24290597 Acc: 1.00000000
iteration 66850 train loss: 0.24375327 Acc: 1.00000000
iteration 66900 train loss: 0.24406660 Acc: 1.00000000
iteration 66950 train loss: 0.24125370 Acc: 1.00000000
iteration 67000 train loss: 0.24257040 Acc: 1.00000000
iteration 67050 train loss: 0.24386157 Acc: 1.00000000
iteration 67100 train loss: 0.25031179 Acc: 1.00000000
iteration 67150 train loss: 0.24120864 Acc: 1.00000000
iteration 67200 train loss: 0.24540989 Acc: 1.00000000
iteration 67250 train loss: 0.24385634 Acc: 1.00000000
iteration 67300 train loss: 0.24253716 Acc: 1.00000000
iteration 67350 train loss: 0.25046036 Acc: 1.00000000
iteration 67400 train loss: 0.24398313 Acc: 1.00000000
iteration 67450 train loss: 0.24395275 Acc: 1.00000000
iteration 67500 train loss: 0.24229768 Acc: 1.00000000
iteration 67550 train loss: 0.24369960 Acc: 1.00000000
iteration 67600 train loss: 0.24150638 Acc: 1.00000000
iteration 67650 train loss: 0.24403876 Acc: 1.00000000
iteration 67700 train loss: 0.27074349 Acc: 0.87500000
iteration 67750 train loss: 0.30743751 Acc: 0.87500000
iteration 67800 train loss: 0.24273567 Acc: 1.00000000
iteration 67850 train loss: 0.24272956 Acc: 1.00000000
iteration 67900 train loss: 0.24239522 Acc: 1.00000000
iteration 67950 train loss: 0.24826451 Acc: 1.00000000
iteration 68000 train loss: 0.24410102 Acc: 1.00000000
iteration 68050 train loss: 0.24464329 Acc: 1.00000000
iteration 68100 train loss: 0.25223851 Acc: 1.00000000
iteration 68150 train loss: 0.24333864 Acc: 1.00000000
iteration 68200 train loss: 0.24277316 Acc: 1.00000000
iteration 68250 train loss: 0.24405563 Acc: 1.00000000
iteration 68300 train loss: 0.24322221 Acc: 1.00000000
iteration 68350 train loss: 0.24927545 Acc: 1.00000000
iteration 68400 train loss: 0.24234538 Acc: 1.00000000
iteration 68450 train loss: 0.24260812 Acc: 1.00000000
iteration 68500 train loss: 0.24322872 Acc: 1.00000000
iteration 68550 train loss: 0.24404199 Acc: 1.00000000
iteration 68600 train loss: 0.24336542 Acc: 1.00000000
iteration 68650 train loss: 0.24240854 Acc: 1.00000000
iteration 68700 train loss: 0.24296898 Acc: 1.00000000
iteration 68750 train loss: 0.24184087 Acc: 1.00000000
iteration 68800 train loss: 0.24397649 Acc: 1.00000000
iteration 68850 train loss: 0.24323459 Acc: 1.00000000
iteration 68900 train loss: 0.25137123 Acc: 1.00000000
iteration 68950 train loss: 0.24689257 Acc: 1.00000000
iteration 69000 train loss: 0.24338457 Acc: 1.00000000
iteration 69050 train loss: 0.24310386 Acc: 1.00000000
iteration 69100 train loss: 0.24350409 Acc: 1.00000000
iteration 69150 train loss: 0.24155624 Acc: 1.00000000
iteration 69200 train loss: 0.24355939 Acc: 1.00000000
iteration 69250 train loss: 0.24573919 Acc: 1.00000000
iteration 69300 train loss: 0.24279746 Acc: 1.00000000
iteration 69350 train loss: 0.26577395 Acc: 0.87500000
iteration 69400 train loss: 0.24361826 Acc: 1.00000000
iteration 69450 train loss: 0.24824245 Acc: 1.00000000
iteration 69500 train loss: 0.24229667 Acc: 1.00000000
iteration 69550 train loss: 0.24208759 Acc: 1.00000000
iteration 69600 train loss: 0.24213190 Acc: 1.00000000
iteration 69650 train loss: 0.24296813 Acc: 1.00000000
iteration 69700 train loss: 0.24235953 Acc: 1.00000000
iteration 69750 train loss: 0.24185559 Acc: 1.00000000
iteration 69800 train loss: 0.24386534 Acc: 1.00000000
iteration 69850 train loss: 0.24280596 Acc: 1.00000000
iteration 69900 train loss: 0.24038321 Acc: 1.00000000
iteration 69950 train loss: 0.24944484 Acc: 1.00000000
iteration 70000 train loss: 0.24304517 Acc: 1.00000000
epoch train loss: 0.24521689 Acc: 0.99292874
 80%|████████  | 8/10 [42:02<10:29, 314.67s/it]epoch val loss: 0.01198538 Acc: 0.97266042
Epoch 9/10
----------
iteration 70050 train loss: 0.24324636 Acc: 1.00000000
iteration 70100 train loss: 0.24343573 Acc: 1.00000000
iteration 70150 train loss: 0.24427237 Acc: 1.00000000
iteration 70200 train loss: 0.24339586 Acc: 1.00000000
iteration 70250 train loss: 0.24491923 Acc: 1.00000000
iteration 70300 train loss: 0.25465345 Acc: 0.87500000
iteration 70350 train loss: 0.24310221 Acc: 1.00000000
iteration 70400 train loss: 0.24213184 Acc: 1.00000000
iteration 70450 train loss: 0.27612925 Acc: 0.87500000
iteration 70500 train loss: 0.28881702 Acc: 0.87500000
iteration 70550 train loss: 0.24162079 Acc: 1.00000000
iteration 70600 train loss: 0.24462622 Acc: 1.00000000
iteration 70650 train loss: 0.24095066 Acc: 1.00000000
iteration 70700 train loss: 0.24528922 Acc: 1.00000000
iteration 70750 train loss: 0.24435332 Acc: 1.00000000
iteration 70800 train loss: 0.24401736 Acc: 1.00000000
iteration 70850 train loss: 0.24119402 Acc: 1.00000000
iteration 70900 train loss: 0.24272375 Acc: 1.00000000
iteration 70950 train loss: 0.24367861 Acc: 1.00000000
iteration 71000 train loss: 0.24281453 Acc: 1.00000000
iteration 71050 train loss: 0.24340563 Acc: 1.00000000
iteration 71100 train loss: 0.24274617 Acc: 1.00000000
iteration 71150 train loss: 0.24297853 Acc: 1.00000000
iteration 71200 train loss: 0.24422759 Acc: 1.00000000
iteration 71250 train loss: 0.24412633 Acc: 1.00000000
iteration 71300 train loss: 0.24244550 Acc: 1.00000000
iteration 71350 train loss: 0.24736090 Acc: 1.00000000
iteration 71400 train loss: 0.24122874 Acc: 1.00000000
iteration 71450 train loss: 0.24799134 Acc: 1.00000000
iteration 71500 train loss: 0.25997180 Acc: 0.87500000
iteration 71550 train loss: 0.24227417 Acc: 1.00000000
iteration 71600 train loss: 0.24282621 Acc: 1.00000000
iteration 71650 train loss: 0.24211019 Acc: 1.00000000
iteration 71700 train loss: 0.24213742 Acc: 1.00000000
iteration 71750 train loss: 0.24438111 Acc: 1.00000000
iteration 71800 train loss: 0.24439678 Acc: 1.00000000
iteration 71850 train loss: 0.24330258 Acc: 1.00000000
iteration 71900 train loss: 0.24367705 Acc: 1.00000000
iteration 71950 train loss: 0.24396899 Acc: 1.00000000
iteration 72000 train loss: 0.24249929 Acc: 1.00000000
iteration 72050 train loss: 0.24206986 Acc: 1.00000000
iteration 72100 train loss: 0.24337046 Acc: 1.00000000
iteration 72150 train loss: 0.24547611 Acc: 1.00000000
iteration 72200 train loss: 0.24142618 Acc: 1.00000000
iteration 72250 train loss: 0.24241684 Acc: 1.00000000
iteration 72300 train loss: 0.24363881 Acc: 1.00000000
iteration 72350 train loss: 0.25331384 Acc: 0.87500000
iteration 72400 train loss: 0.25194260 Acc: 1.00000000
iteration 72450 train loss: 0.24217336 Acc: 1.00000000
iteration 72500 train loss: 0.24192047 Acc: 1.00000000
iteration 72550 train loss: 0.24209841 Acc: 1.00000000
iteration 72600 train loss: 0.24006131 Acc: 1.00000000
iteration 72650 train loss: 0.24408221 Acc: 1.00000000
iteration 72700 train loss: 0.24437667 Acc: 1.00000000
iteration 72750 train loss: 0.24422252 Acc: 1.00000000
iteration 72800 train loss: 0.24316245 Acc: 1.00000000
iteration 72850 train loss: 0.25976649 Acc: 0.87500000
iteration 72900 train loss: 0.24468254 Acc: 1.00000000
iteration 72950 train loss: 0.24275592 Acc: 1.00000000
iteration 73000 train loss: 0.24314676 Acc: 1.00000000
iteration 73050 train loss: 0.24321727 Acc: 1.00000000
iteration 73100 train loss: 0.24917501 Acc: 1.00000000
iteration 73150 train loss: 0.24485694 Acc: 1.00000000
iteration 73200 train loss: 0.24261712 Acc: 1.00000000
iteration 73250 train loss: 0.24280484 Acc: 1.00000000
iteration 73300 train loss: 0.24263079 Acc: 1.00000000
iteration 73350 train loss: 0.24081060 Acc: 1.00000000
iteration 73400 train loss: 0.24479482 Acc: 1.00000000
iteration 73450 train loss: 0.24208987 Acc: 1.00000000
iteration 73500 train loss: 0.24285206 Acc: 1.00000000
iteration 73550 train loss: 0.24381879 Acc: 1.00000000
iteration 73600 train loss: 0.24180953 Acc: 1.00000000
iteration 73650 train loss: 0.24486932 Acc: 1.00000000
iteration 73700 train loss: 0.24384932 Acc: 1.00000000
iteration 73750 train loss: 0.25504309 Acc: 0.87500000
iteration 73800 train loss: 0.24514708 Acc: 1.00000000
iteration 73850 train loss: 0.24199148 Acc: 1.00000000
iteration 73900 train loss: 0.24231312 Acc: 1.00000000
iteration 73950 train loss: 0.24316709 Acc: 1.00000000
iteration 74000 train loss: 0.24263664 Acc: 1.00000000
iteration 74050 train loss: 0.24302518 Acc: 1.00000000
iteration 74100 train loss: 0.24287689 Acc: 1.00000000
iteration 74150 train loss: 0.24083433 Acc: 1.00000000
iteration 74200 train loss: 0.24439242 Acc: 1.00000000
iteration 74250 train loss: 0.24135265 Acc: 1.00000000
iteration 74300 train loss: 0.24200363 Acc: 1.00000000
iteration 74350 train loss: 0.24267611 Acc: 1.00000000
iteration 74400 train loss: 0.24358800 Acc: 1.00000000
iteration 74450 train loss: 0.24315253 Acc: 1.00000000
iteration 74500 train loss: 0.24381979 Acc: 1.00000000
iteration 74550 train loss: 0.24302098 Acc: 1.00000000
iteration 74600 train loss: 0.24480593 Acc: 1.00000000
iteration 74650 train loss: 0.24185985 Acc: 1.00000000
iteration 74700 train loss: 0.24392869 Acc: 1.00000000
iteration 74750 train loss: 0.24265550 Acc: 1.00000000
iteration 74800 train loss: 0.24282968 Acc: 1.00000000
iteration 74850 train loss: 0.24208134 Acc: 1.00000000
iteration 74900 train loss: 0.24148062 Acc: 1.00000000
iteration 74950 train loss: 0.24362741 Acc: 1.00000000
iteration 75000 train loss: 0.24341905 Acc: 1.00000000
iteration 75050 train loss: 0.24338494 Acc: 1.00000000
iteration 75100 train loss: 0.24553226 Acc: 1.00000000
iteration 75150 train loss: 0.24263322 Acc: 1.00000000
iteration 75200 train loss: 0.24396752 Acc: 1.00000000
iteration 75250 train loss: 0.31277496 Acc: 0.87500000
iteration 75300 train loss: 0.24247995 Acc: 1.00000000
iteration 75350 train loss: 0.24504229 Acc: 1.00000000
iteration 75400 train loss: 0.24186733 Acc: 1.00000000
iteration 75450 train loss: 0.24307667 Acc: 1.00000000
iteration 75500 train loss: 0.24276024 Acc: 1.00000000
iteration 75550 train loss: 0.26116657 Acc: 0.87500000
iteration 75600 train loss: 0.25079054 Acc: 1.00000000
iteration 75650 train loss: 0.24388009 Acc: 1.00000000
iteration 75700 train loss: 0.24450356 Acc: 1.00000000
iteration 75750 train loss: 0.26611161 Acc: 0.87500000
iteration 75800 train loss: 0.24407239 Acc: 1.00000000
iteration 75850 train loss: 0.24048321 Acc: 1.00000000
iteration 75900 train loss: 0.24259591 Acc: 1.00000000
iteration 75950 train loss: 0.24277511 Acc: 1.00000000
iteration 76000 train loss: 0.24283384 Acc: 1.00000000
iteration 76050 train loss: 0.24839145 Acc: 1.00000000
iteration 76100 train loss: 0.24454144 Acc: 1.00000000
iteration 76150 train loss: 0.24286169 Acc: 1.00000000
iteration 76200 train loss: 0.24312782 Acc: 1.00000000
iteration 76250 train loss: 0.24162161 Acc: 1.00000000
iteration 76300 train loss: 0.24414179 Acc: 1.00000000
iteration 76350 train loss: 0.24458683 Acc: 1.00000000
iteration 76400 train loss: 0.24222869 Acc: 1.00000000
iteration 76450 train loss: 0.24425277 Acc: 1.00000000
iteration 76500 train loss: 0.24220674 Acc: 1.00000000
iteration 76550 train loss: 0.24432206 Acc: 1.00000000
iteration 76600 train loss: 0.24282506 Acc: 1.00000000
iteration 76650 train loss: 0.24260192 Acc: 1.00000000
iteration 76700 train loss: 0.24138556 Acc: 1.00000000
iteration 76750 train loss: 0.24081841 Acc: 1.00000000
iteration 76800 train loss: 0.24354866 Acc: 1.00000000
iteration 76850 train loss: 0.24250641 Acc: 1.00000000
iteration 76900 train loss: 0.24334829 Acc: 1.00000000
iteration 76950 train loss: 0.25168791 Acc: 1.00000000
iteration 77000 train loss: 0.24316980 Acc: 1.00000000
iteration 77050 train loss: 0.24641746 Acc: 1.00000000
iteration 77100 train loss: 0.24339975 Acc: 1.00000000
iteration 77150 train loss: 0.24314272 Acc: 1.00000000
iteration 77200 train loss: 0.24234538 Acc: 1.00000000
iteration 77250 train loss: 0.24427254 Acc: 1.00000000
iteration 77300 train loss: 0.24259575 Acc: 1.00000000
iteration 77350 train loss: 0.24351132 Acc: 1.00000000
iteration 77400 train loss: 0.24387233 Acc: 1.00000000
iteration 77450 train loss: 0.24290659 Acc: 1.00000000
iteration 77500 train loss: 0.24228929 Acc: 1.00000000
iteration 77550 train loss: 0.25350401 Acc: 1.00000000
iteration 77600 train loss: 0.24367680 Acc: 1.00000000
iteration 77650 train loss: 0.24400422 Acc: 1.00000000
iteration 77700 train loss: 0.24098903 Acc: 1.00000000
iteration 77750 train loss: 0.24409251 Acc: 1.00000000
iteration 77800 train loss: 0.24162762 Acc: 1.00000000
iteration 77850 train loss: 0.24221194 Acc: 1.00000000
iteration 77900 train loss: 0.24287000 Acc: 1.00000000
iteration 77950 train loss: 0.24340440 Acc: 1.00000000
iteration 78000 train loss: 0.24194729 Acc: 1.00000000
iteration 78050 train loss: 0.25637081 Acc: 0.87500000
iteration 78100 train loss: 0.24394828 Acc: 1.00000000
iteration 78150 train loss: 0.24374013 Acc: 1.00000000
iteration 78200 train loss: 0.24898174 Acc: 1.00000000
iteration 78250 train loss: 0.24205939 Acc: 1.00000000
iteration 78300 train loss: 0.24360615 Acc: 1.00000000
iteration 78350 train loss: 0.24196281 Acc: 1.00000000
iteration 78400 train loss: 0.24388593 Acc: 1.00000000
iteration 78450 train loss: 0.24272580 Acc: 1.00000000
iteration 78500 train loss: 0.24247083 Acc: 1.00000000
iteration 78550 train loss: 0.24303123 Acc: 1.00000000
iteration 78600 train loss: 0.24410434 Acc: 1.00000000
iteration 78650 train loss: 0.24252762 Acc: 1.00000000
iteration 78700 train loss: 0.24441230 Acc: 1.00000000
iteration 78750 train loss: 0.23936282 Acc: 1.00000000
epoch train loss: nan Acc: 0.99405730
 90%|█████████ | 9/10 [47:16<05:14, 314.48s/it]epoch val loss: 0.01352694 Acc: 0.96708089
Epoch 10/10
----------
iteration 78800 train loss: 0.24200149 Acc: 1.00000000
iteration 78850 train loss: 0.24378495 Acc: 1.00000000
iteration 78900 train loss: 0.24292856 Acc: 1.00000000
iteration 78950 train loss: 0.24349740 Acc: 1.00000000
iteration 79000 train loss: 0.24235769 Acc: 1.00000000
iteration 79050 train loss: 0.24428006 Acc: 1.00000000
iteration 79100 train loss: 0.24281003 Acc: 1.00000000
iteration 79150 train loss: 0.24197392 Acc: 1.00000000
iteration 79200 train loss: 0.24291414 Acc: 1.00000000
iteration 79250 train loss: 0.24230482 Acc: 1.00000000
iteration 79300 train loss: 0.24220952 Acc: 1.00000000
iteration 79350 train loss: 0.24315961 Acc: 1.00000000
iteration 79400 train loss: 0.24448532 Acc: 1.00000000
iteration 79450 train loss: 0.24358608 Acc: 1.00000000
iteration 79500 train loss: 0.24186303 Acc: 1.00000000
iteration 79550 train loss: 0.24285173 Acc: 1.00000000
iteration 79600 train loss: 0.28208485 Acc: 0.87500000
iteration 79650 train loss: 0.24414898 Acc: 1.00000000
iteration 79700 train loss: 0.24583086 Acc: 1.00000000
iteration 79750 train loss: 0.24332631 Acc: 1.00000000
iteration 79800 train loss: 0.24254607 Acc: 1.00000000
iteration 79850 train loss: 0.24187715 Acc: 1.00000000
iteration 79900 train loss: 0.24396847 Acc: 1.00000000
iteration 79950 train loss: 0.23972428 Acc: 1.00000000
iteration 80000 train loss: 0.24603245 Acc: 1.00000000
iteration 80050 train loss: 0.24359211 Acc: 1.00000000
iteration 80100 train loss: 0.24099837 Acc: 1.00000000
iteration 80150 train loss: 0.24390486 Acc: 1.00000000
iteration 80200 train loss: 0.24930751 Acc: 1.00000000
iteration 80250 train loss: 0.24123017 Acc: 1.00000000
iteration 80300 train loss: 0.24298421 Acc: 1.00000000
iteration 80350 train loss: 0.24283347 Acc: 1.00000000
iteration 80400 train loss: 0.24225827 Acc: 1.00000000
iteration 80450 train loss: 0.24195747 Acc: 1.00000000
iteration 80500 train loss: 0.24363077 Acc: 1.00000000
iteration 80550 train loss: 0.25162023 Acc: 1.00000000
iteration 80600 train loss: 0.24290486 Acc: 1.00000000
iteration 80650 train loss: 0.24040227 Acc: 1.00000000
iteration 80700 train loss: 0.24338099 Acc: 1.00000000
iteration 80750 train loss: 0.24205439 Acc: 1.00000000
iteration 80800 train loss: 0.23919804 Acc: 1.00000000
iteration 80850 train loss: 0.29134372 Acc: 0.87500000
iteration 80900 train loss: 0.25145733 Acc: 1.00000000
iteration 80950 train loss: 0.24237664 Acc: 1.00000000
iteration 81000 train loss: 0.24241798 Acc: 1.00000000
iteration 81050 train loss: 0.24450432 Acc: 1.00000000
iteration 81100 train loss: 0.24632531 Acc: 1.00000000
iteration 81150 train loss: 0.25053936 Acc: 1.00000000
iteration 81200 train loss: 0.24374515 Acc: 1.00000000
iteration 81250 train loss: 0.24141088 Acc: 1.00000000
iteration 81300 train loss: 0.24413297 Acc: 1.00000000
iteration 81350 train loss: 0.25130731 Acc: 1.00000000
iteration 81400 train loss: 0.24170971 Acc: 1.00000000
iteration 81450 train loss: 0.24434280 Acc: 1.00000000
iteration 81500 train loss: 0.24489208 Acc: 1.00000000
iteration 81550 train loss: 0.24256122 Acc: 1.00000000
iteration 81600 train loss: 0.24080615 Acc: 1.00000000
iteration 81650 train loss: 0.24460573 Acc: 1.00000000
iteration 81700 train loss: 0.24343219 Acc: 1.00000000
iteration 81750 train loss: 0.24250500 Acc: 1.00000000
iteration 81800 train loss: 0.24436273 Acc: 1.00000000
iteration 81850 train loss: 0.24360085 Acc: 1.00000000
iteration 81900 train loss: 0.24251533 Acc: 1.00000000
iteration 81950 train loss: 0.24392107 Acc: 1.00000000
iteration 82000 train loss: 0.24255431 Acc: 1.00000000
iteration 82050 train loss: 0.24898490 Acc: 1.00000000
iteration 82100 train loss: 0.24312480 Acc: 1.00000000
iteration 82150 train loss: 0.24063498 Acc: 1.00000000
iteration 82200 train loss: 0.25465798 Acc: 1.00000000
iteration 82250 train loss: 0.24256535 Acc: 1.00000000
iteration 82300 train loss: 0.24120975 Acc: 1.00000000
iteration 82350 train loss: 0.24173778 Acc: 1.00000000
iteration 82400 train loss: 0.24306285 Acc: 1.00000000
iteration 82450 train loss: 0.24462421 Acc: 1.00000000
iteration 82500 train loss: 0.24049816 Acc: 1.00000000
iteration 82550 train loss: 0.24347334 Acc: 1.00000000
iteration 82600 train loss: 0.24247532 Acc: 1.00000000
iteration 82650 train loss: 0.24127112 Acc: 1.00000000
iteration 82700 train loss: 0.24352615 Acc: 1.00000000
iteration 82750 train loss: 0.24331342 Acc: 1.00000000
iteration 82800 train loss: 0.24134149 Acc: 1.00000000
iteration 82850 train loss: 0.24649693 Acc: 1.00000000
iteration 82900 train loss: 0.24391389 Acc: 1.00000000
iteration 82950 train loss: 0.24340190 Acc: 1.00000000
iteration 83000 train loss: 0.24350064 Acc: 1.00000000
iteration 83050 train loss: 0.24182594 Acc: 1.00000000
iteration 83100 train loss: 0.24256974 Acc: 1.00000000
iteration 83150 train loss: 0.24330531 Acc: 1.00000000
iteration 83200 train loss: 0.25266659 Acc: 1.00000000
iteration 83250 train loss: 0.24212939 Acc: 1.00000000
iteration 83300 train loss: 0.24171723 Acc: 1.00000000
iteration 83350 train loss: 0.24344832 Acc: 1.00000000
iteration 83400 train loss: 0.24246210 Acc: 1.00000000
iteration 83450 train loss: 0.24415588 Acc: 1.00000000
iteration 83500 train loss: 0.24202961 Acc: 1.00000000
iteration 83550 train loss: 0.24833225 Acc: 1.00000000
iteration 83600 train loss: 0.24153352 Acc: 1.00000000
iteration 83650 train loss: 0.24278070 Acc: 1.00000000
iteration 83700 train loss: 0.24177843 Acc: 1.00000000
iteration 83750 train loss: 0.24659424 Acc: 1.00000000
iteration 83800 train loss: 0.24641736 Acc: 1.00000000
iteration 83850 train loss: 0.24425943 Acc: 1.00000000
iteration 83900 train loss: 0.24410349 Acc: 1.00000000
iteration 83950 train loss: 0.24404995 Acc: 1.00000000
iteration 84000 train loss: 0.24394715 Acc: 1.00000000
iteration 84050 train loss: 0.24455330 Acc: 1.00000000
iteration 84100 train loss: 0.24402204 Acc: 1.00000000
iteration 84150 train loss: 0.24219054 Acc: 1.00000000
iteration 84200 train loss: 0.24341260 Acc: 1.00000000
iteration 84250 train loss: 0.24334134 Acc: 1.00000000
iteration 84300 train loss: 0.24328940 Acc: 1.00000000
iteration 84350 train loss: 0.24149451 Acc: 1.00000000
iteration 84400 train loss: 0.24248874 Acc: 1.00000000
iteration 84450 train loss: 0.25547773 Acc: 0.87500000
iteration 84500 train loss: 0.24457932 Acc: 1.00000000
iteration 84550 train loss: 0.24317893 Acc: 1.00000000
iteration 84600 train loss: 0.24349800 Acc: 1.00000000
iteration 84650 train loss: 0.24499954 Acc: 1.00000000
iteration 84700 train loss: 0.24087127 Acc: 1.00000000
iteration 84750 train loss: 0.24113698 Acc: 1.00000000
iteration 84800 train loss: 0.24309483 Acc: 1.00000000
iteration 84850 train loss: 0.24255198 Acc: 1.00000000
iteration 84900 train loss: 0.25342527 Acc: 1.00000000
iteration 84950 train loss: 0.24270749 Acc: 1.00000000
iteration 85000 train loss: 0.24340302 Acc: 1.00000000
iteration 85050 train loss: 0.24346328 Acc: 1.00000000
iteration 85100 train loss: 0.24116021 Acc: 1.00000000
iteration 85150 train loss: 0.24247703 Acc: 1.00000000
iteration 85200 train loss: 0.24249852 Acc: 1.00000000
iteration 85250 train loss: 0.24407744 Acc: 1.00000000
iteration 85300 train loss: 0.24332078 Acc: 1.00000000
iteration 85350 train loss: 0.24159266 Acc: 1.00000000
iteration 85400 train loss: 0.24601205 Acc: 1.00000000
iteration 85450 train loss: 0.24280147 Acc: 1.00000000
iteration 85500 train loss: 0.24413140 Acc: 1.00000000
iteration 85550 train loss: 0.24244988 Acc: 1.00000000
iteration 85600 train loss: 0.24071385 Acc: 1.00000000
iteration 85650 train loss: 0.24309783 Acc: 1.00000000
iteration 85700 train loss: 0.24350977 Acc: 1.00000000
iteration 85750 train loss: 0.24447438 Acc: 1.00000000
iteration 85800 train loss: 0.24764158 Acc: 1.00000000
iteration 85850 train loss: 0.24404968 Acc: 1.00000000
iteration 85900 train loss: 0.24314868 Acc: 1.00000000
iteration 85950 train loss: 0.24469802 Acc: 1.00000000
iteration 86000 train loss: 0.26166555 Acc: 0.87500000
iteration 86050 train loss: 0.24469429 Acc: 1.00000000
iteration 86100 train loss: 0.24303590 Acc: 1.00000000
iteration 86150 train loss: 0.24668278 Acc: 1.00000000
iteration 86200 train loss: 0.24216489 Acc: 1.00000000
iteration 86250 train loss: 0.24218816 Acc: 1.00000000
iteration 86300 train loss: 0.24395813 Acc: 1.00000000
iteration 86350 train loss: 0.24421608 Acc: 1.00000000
iteration 86400 train loss: 0.24217279 Acc: 1.00000000
iteration 86450 train loss: 0.24773684 Acc: 1.00000000
iteration 86500 train loss: 0.24173042 Acc: 1.00000000
iteration 86550 train loss: 0.24252425 Acc: 1.00000000
iteration 86600 train loss: 0.24372628 Acc: 1.00000000
iteration 86650 train loss: 0.24901845 Acc: 1.00000000
iteration 86700 train loss: 0.26273456 Acc: 0.87500000
iteration 86750 train loss: 0.24495144 Acc: 1.00000000
iteration 86800 train loss: 0.24552518 Acc: 1.00000000
iteration 86850 train loss: 0.24225852 Acc: 1.00000000
iteration 86900 train loss: 0.24350402 Acc: 1.00000000
iteration 86950 train loss: 0.24315193 Acc: 1.00000000
iteration 87000 train loss: 0.24283651 Acc: 1.00000000
iteration 87050 train loss: 0.26450011 Acc: 0.87500000
iteration 87100 train loss: 0.24072002 Acc: 1.00000000
iteration 87150 train loss: 0.24321240 Acc: 1.00000000
iteration 87200 train loss: 0.24567781 Acc: 1.00000000
iteration 87250 train loss: 0.24345334 Acc: 1.00000000
iteration 87300 train loss: 0.24208939 Acc: 1.00000000
iteration 87350 train loss: 0.24406894 Acc: 1.00000000
iteration 87400 train loss: 0.25463521 Acc: 1.00000000
iteration 87450 train loss: 0.24720107 Acc: 1.00000000
iteration 87500 train loss: 0.24318258 Acc: 1.00000000
epoch train loss: nan Acc: 0.99504298
100%|██████████| 10/10 [52:30<00:00, 314.37s/it]100%|██████████| 10/10 [52:30<00:00, 315.04s/it]
epoch val loss: 0.01675987 Acc: 0.96814609
Best val Acc: 0.9727
